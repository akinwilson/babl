{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to pytorch lightning fitting routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorboard\n",
    "?TextDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from babl.data import TextDataset, TextDataModule\n",
    "from babl.utils import CallbackCollection\n",
    "from babl.routine import Routine\n",
    "\n",
    "\n",
    "WHITE='\\033[1:97m]' \n",
    "RESET='\\033[0m'\n",
    "s = \"\"\"\n",
    "                                                                                \n",
    "                            @@@@@@@@@@@@@@@@@@@@@@@@@                           \n",
    "                      ,@@@@@@@@@@@            #@@@@@@@@@@@                      \n",
    "                   @@@@@@      @@@@           @@@      @@@@@@&                  \n",
    "                @@@@@          &@@@   ,@@@@@@@@@@          @@@@@.               \n",
    "              @@@@@@      @@@@@@@@@   ,@@@   /@@   @@@      @@@@@@@             \n",
    "            @@@@  @@@@@    @@@@       ,@@@        @@@@@@@@@@@@# @@@@@           \n",
    "          @@@@      @@@@@   @@@@  .@@@@@@@@@@@  @@@@   @@@@@      @@@@          \n",
    "         @@@@     @@@@@       @@@@@@@@@@@@@@@@@@@@@                 @@@@        \n",
    "        @@@@     @@@@@.    @@@@@@@@   ,@@@   @@@@@@@@@    @@@@@@     @@@@       \n",
    "       @@@@         @@@@@@@@@    @@@@@@@@@@@@@@@   @@@@@@@@@@@@@@     @@@(      \n",
    "      @@@@@@@@@@@@(     @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@     @@@@@@@@@@@@      \n",
    "      @@@.    @@@@     @@@  %@@@@@@@@@@@@@@@@@@@@@@@  @@@@     @@      @@@&     \n",
    "      @@@     @@@     @@@@  @@@@@@@@@@@@@@@@@@@@@@@@   @@@             @@@@     \n",
    "      @@@     @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@    @@@@     \n",
    "      @@@             @@@@  @@@@@@@@@@@@@@@@@@@@@@@@   @@@     @@@#    @@@@     \n",
    "      @@@(    @@@@     @@@  @@@@@@@@@@@@@@@@@@@@@@@@@ @@@@     @@@.    @@@#     \n",
    "      @@@@@@@@@@@@@    %@@@@@@.@@@@@@@@@@@@@@@@@@@@@@@@@@     &@@@@@@@@@@@      \n",
    "       @@@@     @@@@@@@@@@@@@@  @@@@@@@@@@@@@@@@   @@@@@@@@@@.        @@@       \n",
    "        @@@@     @@@@@     @@@@@@@@    @@@    @@@@@@@      @@@@.     @@@#       \n",
    "         @@@@                %@@@@@@@@@@@@@@@@@@@@@      %@@@@     /@@@         \n",
    "          @@@@@     @@@@@@  @@@@    @@@@@@@@%   #@@@#  *@@@@.     @@@@          \n",
    "            @@@@, @@@@/@@@@@@@@        @@@        @@@@    @@@@@ @@@@            \n",
    "              @@@@@@       @@   @@@@%  @@@  .@@@@@@@@@      /@@@@@,             \n",
    "                @@@@@@          @@@@@@@@@@   @@@@          @@@@@                \n",
    "                   @@@@@@@     @@@@           @@@(     @@@@@@                   \n",
    "                       @@@@@@@@@@@            .@@@@@@@@@@                       \n",
    "                            .@@@@@@@@@@@@@@@@@@@@@@@                            \n",
    "                                                                                \n",
    "                                                                                \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Fitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        model_name,\n",
    "        data_args,\n",
    "        mini_dataset = True, \n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_name = model_name\n",
    "        self.args = data_args\n",
    "        self.mini_dataset = mini_dataset\n",
    "        self.data_module = TextDataModule(data_args=data_args, tokenizer=tokenizer, mini_dataset=mini_dataset) \n",
    "        self.trainer = None\n",
    "        ####################################################################################\n",
    "        @dataclass\n",
    "        class FittingArgs:\n",
    "            es_patience: int = 2\n",
    "            model_dir = Path(\"/home/nameduser/Code/babl/outputs\") / model_name\n",
    "            max_epoch: int = 5\n",
    "            fast_dev_run: bool = False\n",
    "            mini_dataset: bool = True \n",
    "            def __post_init__(self):\n",
    "                self.model_dir.mkdir(parents=True, exist_ok=True)\n",
    "                self.model_dir  =  str(self.model_dir)\n",
    "\n",
    "        ####################################################################################\n",
    "\n",
    "        self.args = FittingArgs()\n",
    "\n",
    "    def setup(self):\n",
    "        train_loader = self.data_module.train_dataloader()\n",
    "        val_loader = self.data_module.val_dataloader()\n",
    "        test_loader = self.data_module.test_dataloader()\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    def callbacks(self):\n",
    "        # cfg_fitting = self.cfg_fitting\n",
    "        callback_collection = CallbackCollection(self.args)\n",
    "        return callback_collection()\n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=self.args.model_dir,\n",
    "            name=\"lightning_logs\",\n",
    "        )\n",
    "        # Model = self.model\n",
    "        # get loaders and datamodule to access input shape\n",
    "        train_loader, val_loader, test_loader = self.setup()\n",
    "        print(\"Created training, validating and test loaders .... \")\n",
    "        # get input shape for onnx exporting\n",
    "        # input_shape = data_module.input_shape\n",
    "        # init model\n",
    "        # kwargs = {}\n",
    "        # model = Model(**kwargs)\n",
    "\n",
    "        # setup training, validating and testing routines for the model\n",
    "        routine = Routine(self.model)\n",
    "\n",
    "        # Init a trainer to execute routine\n",
    "        callback_dict = self.callbacks()\n",
    "        callback_list = [v for (_, v) in callback_dict.items()]\n",
    "        number_devices = os.getenv(\"CUDA_VISIBLE_DEVICES\", \"1,\").split(\",\")\n",
    "        try:\n",
    "            number_devices.remove(\"\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        self.trainer = Trainer(\n",
    "            accelerator=\"cpu\",\n",
    "            devices=len(number_devices),\n",
    "            # strategy=os.getenv(\"STRATEGY\", \"ddp_notebook\"),\n",
    "            sync_batchnorm=True,\n",
    "            logger=logger,\n",
    "            max_epochs=self.args.max_epoch,\n",
    "            callbacks=callback_list,\n",
    "            num_sanity_val_steps=2,\n",
    "            # resume_from_checkpoint=self.cfg_fitting.resume_from_checkpoint,\n",
    "            gradient_clip_val=1.0,\n",
    "            fast_dev_run=self.args.fast_dev_run,\n",
    "        )\n",
    "\n",
    "        self.trainer.fit(\n",
    "            routine, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "        )  # ,ckpt_path=PATH)\n",
    "\n",
    "        if self.args.fast_dev_run:\n",
    "            # issue with finding best weights path for in fast dev run using last model weights\n",
    "            model_ckpt_path = callback_dict[\"checkpoint\"].__dict__[\"last_model_path\"]\n",
    "        else:\n",
    "            model_ckpt_path = callback_dict[\"checkpoint\"].__dict__[\"best_model_path\"]\n",
    "\n",
    "        self.trainer.test(\n",
    "            dataloaders=test_loader,\n",
    "            ckpt_path=model_ckpt_path,\n",
    "        )\n",
    "        print(WHITE + s + RESET)\n",
    "        # Return the input_shapes and trainer of the model for exporting\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=t5\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME=t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting(es_patience=2, model_dir='/home/nameduser/Code/babl/outputs/t5-small', max_epoch=5, fast_dev_run=False, mini_dataset=True)\n"
     ]
    }
   ],
   "source": [
    "from babl.models import MODELS_CHOICES, MODELS\n",
    "from babl.config import T5 as T5Config\n",
    "from pathlib import Path\n",
    "import os \n",
    "from babl.config import Fitting as FittingArgs\n",
    "\n",
    "args = FittingArgs()\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINI DATASET RUN?: True. Using 128 datapoints for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:289: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINI DATASET RUN?: True. Using 128 datapoints for training\n",
      "MINI DATASET RUN?: True. Using 128 datapoints for training\n",
      "Created training, validating and test loaders .... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/nameduser/Code/babl/outputs/t5-small exists and is not empty.\n",
      "\n",
      "  | Name  | Type                       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M | train\n",
      "-------------------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n",
      "277       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f65939c24f4ae7b0d6fdc87074e0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1945cc894fb24a64a9f98058157a37f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7d1f4ebacb48c3a8b5f20c8388864c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d2caaf0a084cd1a43a999dd845776a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2139639361e548008cf66f21334920e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/nameduser/Code/babl/outputs/t5-small/epoch=0-val_loss=10.76-val_EM=0.98-val_F1=0.90.ckpt\n",
      "Loaded model weights from the checkpoint at /home/nameduser/Code/babl/outputs/t5-small/epoch=0-val_loss=10.76-val_EM=0.98-val_F1=0.90.ckpt\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:476: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469845eba1b44acbbe8e5e7a59f1d75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_EM          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9843579530715942     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_F1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8000000715255737     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_EM         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9843579530715942    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_F1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8000000715255737    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1:97m]\n",
      "                                                                                \n",
      "                            @@@@@@@@@@@@@@@@@@@@@@@@@                           \n",
      "                      ,@@@@@@@@@@@            #@@@@@@@@@@@                      \n",
      "                   @@@@@@      @@@@           @@@      @@@@@@&                  \n",
      "                @@@@@          &@@@   ,@@@@@@@@@@          @@@@@.               \n",
      "              @@@@@@      @@@@@@@@@   ,@@@   /@@   @@@      @@@@@@@             \n",
      "            @@@@  @@@@@    @@@@       ,@@@        @@@@@@@@@@@@# @@@@@           \n",
      "          @@@@      @@@@@   @@@@  .@@@@@@@@@@@  @@@@   @@@@@      @@@@          \n",
      "         @@@@     @@@@@       @@@@@@@@@@@@@@@@@@@@@                 @@@@        \n",
      "        @@@@     @@@@@.    @@@@@@@@   ,@@@   @@@@@@@@@    @@@@@@     @@@@       \n",
      "       @@@@         @@@@@@@@@    @@@@@@@@@@@@@@@   @@@@@@@@@@@@@@     @@@(      \n",
      "      @@@@@@@@@@@@(     @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@     @@@@@@@@@@@@      \n",
      "      @@@.    @@@@     @@@  %@@@@@@@@@@@@@@@@@@@@@@@  @@@@     @@      @@@&     \n",
      "      @@@     @@@     @@@@  @@@@@@@@@@@@@@@@@@@@@@@@   @@@             @@@@     \n",
      "      @@@     @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@    @@@@     \n",
      "      @@@             @@@@  @@@@@@@@@@@@@@@@@@@@@@@@   @@@     @@@#    @@@@     \n",
      "      @@@(    @@@@     @@@  @@@@@@@@@@@@@@@@@@@@@@@@@ @@@@     @@@.    @@@#     \n",
      "      @@@@@@@@@@@@@    %@@@@@@.@@@@@@@@@@@@@@@@@@@@@@@@@@     &@@@@@@@@@@@      \n",
      "       @@@@     @@@@@@@@@@@@@@  @@@@@@@@@@@@@@@@   @@@@@@@@@@.        @@@       \n",
      "        @@@@     @@@@@     @@@@@@@@    @@@    @@@@@@@      @@@@.     @@@#       \n",
      "         @@@@                %@@@@@@@@@@@@@@@@@@@@@      %@@@@     /@@@         \n",
      "          @@@@@     @@@@@@  @@@@    @@@@@@@@%   #@@@#  *@@@@.     @@@@          \n",
      "            @@@@, @@@@/@@@@@@@@        @@@        @@@@    @@@@@ @@@@            \n",
      "              @@@@@@       @@   @@@@%  @@@  .@@@@@@@@@      /@@@@@,             \n",
      "                @@@@@@          @@@@@@@@@@   @@@@          @@@@@                \n",
      "                   @@@@@@@     @@@@           @@@(     @@@@@@                   \n",
      "                       @@@@@@@@@@@            .@@@@@@@@@@                       \n",
      "                            .@@@@@@@@@@@@@@@@@@@@@@@                            \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001b[0m\n",
      "self.x_out='1995'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/onnx/utils.py:1963: UserWarning: Provided key question with context for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\n",
      "/home/nameduser/Code/babl/models/src/babl/utils.py:95: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  ans_encoded = self.m.generate(input_ids=torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:1846: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return torch.tensor(token, device=device, dtype=torch.long)\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:1881: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  eos_token_tensor is not None\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:1890: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if eos_token_tensor is not None and (\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:1401: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if has_default_max_length and generation_config.max_new_tokens is None and generation_config.max_length == 20:\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:1409: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_ids_length >= generation_config.max_length:\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:1426: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if generation_config.min_length is not None and generation_config.min_length > generation_config.max_length:\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:2119: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs_tensor.shape[1] != input_ids_length\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:388: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  or (is_torchdynamo_compiling() or cache_position[-1] >= input_ids.shape[1])  # Exception 3\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:391: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif input_ids.shape[1] != cache_position.shape[0]:  # Default case (the \"else\", a no op, is Exception 2)\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1306: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sequence_length != 1:\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/generation/utils.py:2453: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  elif this_peer_finished:\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/cache_utils.py:460: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  or len(self.key_cache[layer_idx]) == 0  # the layer has no cache\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/cache_utils.py:444: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  len(self.key_cache[layer_idx]) == 0\n",
      "/home/nameduser/Code/babl/models/src/babl/utils.py:97: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  return clean(\"\".join([self.decode(x) for x in ans_encoded]))\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/utils/generic.py:262: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  \"pt\": lambda obj: obj.detach().cpu().tolist(),\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0 INTERNAL ASSERT FAILED at \"../torch/csrc/jit/ir/alias_analysis.cpp\":617, please report a bug to PyTorch. We don't have an op for aten::full but it isn't a special case.  Argument types: int[], bool, int, NoneType, Device, bool, \n\nCandidates:\n\taten::full.names(int[] size, Scalar fill_value, *, str[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor\n\taten::full(SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor\n\taten::full.names_out(int[] size, Scalar fill_value, *, str[]? names, Tensor(a!) out) -> Tensor(a!)\n\taten::full.out(SymInt[] size, Scalar fill_value, *, Tensor(a!) out) -> Tensor(a!)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbabl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Fitting \u001b[38;5;28;01mas\u001b[39;00m FittingArgs\n\u001b[1;32m     55\u001b[0m args \u001b[38;5;241m=\u001b[39m FittingArgs()\n\u001b[0;32m---> 56\u001b[0m \u001b[43mOnnxExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/babl/models/src/babl/utils.py:163\u001b[0m, in \u001b[0;36mOnnxExporter.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    161\u001b[0m positional_inputs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion: how old are you\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext: I was born 1995\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# model being run\u001b[39;49;00m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositional_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# model input (or a tuple for multiple inputs)\u001b[39;49;00m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# where to save the model (can be a file or file-like object)\u001b[39;49;00m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# store the trained parameter weights inside the model file\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Only certain operations are available, 17 includes FFTs and IFFTs\u001b[39;49;00m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# whether to execute constant folding for optimization\u001b[39;49;00m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# the model's input names\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# the model's output names\u001b[39;49;00m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion with context\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# variable length axes\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_session()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/onnx/__init__.py:375\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, report, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exporter only supports dynamic shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[0;32m--> 375\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/onnx/utils.py:502\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;241m+\u001b[39m (kwargs,)\n\u001b[0;32m--> 502\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/onnx/utils.py:1564\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1562\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1564\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1579\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1580\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/onnx/utils.py:1113\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1112\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1113\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/onnx/utils.py:997\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    992\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m    993\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 997\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    999\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/onnx/utils.py:904\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    902\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    903\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 904\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    913\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/jit/_trace.py:1500\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1499\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1500\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/torch/jit/_trace.py:139\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 139\u001b[0m graph, out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[38;5;241m0\u001b[39m], ret_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0 INTERNAL ASSERT FAILED at \"../torch/csrc/jit/ir/alias_analysis.cpp\":617, please report a bug to PyTorch. We don't have an op for aten::full but it isn't a special case.  Argument types: int[], bool, int, NoneType, Device, bool, \n\nCandidates:\n\taten::full.names(int[] size, Scalar fill_value, *, str[]? names, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor\n\taten::full(SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor\n\taten::full.names_out(int[] size, Scalar fill_value, *, str[]? names, Tensor(a!) out) -> Tensor(a!)\n\taten::full.out(SymInt[] size, Scalar fill_value, *, Tensor(a!) out) -> Tensor(a!)"
     ]
    }
   ],
   "source": [
    "from babl.models import MODELS_CHOICES, MODELS\n",
    "from babl.config import T5 as T5Config\n",
    "from babl.config import Data as DataArgs\n",
    "from pathlib import Path\n",
    "import os \n",
    "# from babl.config import FittingArgs\n",
    "\n",
    "model_name = \"t5\"\n",
    "full_model_name = MODELS_CHOICES[model_name][0]\n",
    "t_w_m = MODELS[model_name]\n",
    "\n",
    "t = t_w_m[\"tok\"]\n",
    "m = t_w_m[\"model\"]\n",
    "\n",
    "tokenizer = t.from_pretrained(full_model_name)\n",
    "model = m.from_pretrained(full_model_name, **T5Config().__dict__)\n",
    "model.train()\n",
    "\n",
    "\n",
    "# overwritting the MODEL_NAME with the full version\n",
    "os.environ['MODEL_NAME'] = full_model_name\n",
    "# changing this env variable after initilising the FittingArguments doesnt change \n",
    "# the root directoy\n",
    "# placing in training mode \n",
    "\n",
    "\n",
    "\n",
    "data_path_root = Path(\"/home/nameduser/Code/babl/inputs\") \n",
    "# data_path_val = data_path_root / \"10k.jsonl\"\n",
    "# ds = TextDataset(data_path_val, tokenizer=tokenizer, plain_text=False)\n",
    "# from babl.data import T2TDataCollator\n",
    "# from torch.utils.data import DataLoader\n",
    "# t_dl = DataLoader(ds, batch_size=64, shuffle=True, collate_fn=T2TDataCollator())\n",
    "# # test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "# data_module = TextDataModule(data_path_root, tokenizer)\n",
    "\n",
    "fitter= Fitter(model=model, model_name=full_model_name, tokenizer=tokenizer, data_args=DataArgs())()\n",
    "\n",
    "\n",
    "from babl.utils import OnnxExporter, Predictor \n",
    "from babl.config import Data as DataArgs\n",
    "import torch \n",
    "# os.environ['MODEL_NAME']\n",
    "\n",
    "\n",
    "# during distributed training accessing the model is further down the module tree\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() == 1:\n",
    "    model = fitter.trainer.model.model\n",
    "    # fitter.trainer.model\n",
    "    tokenizer = fitter.data_module.tokenizer\n",
    "\n",
    "args = DataArgs()\n",
    "predictor = Predictor(tokenizer=tokenizer, model=model, input_max_len=args.input_max_len)\n",
    "import pickle\n",
    "from babl.config import Fitting as FittingArgs\n",
    "args = FittingArgs()\n",
    "with open(Path(args.model_dir) / \"model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(predictor, f)\n",
    "with open(Path(args.model_dir) / \"model.pickle\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "loaded_model(\"Where is london\", \"\")\n",
    "\n",
    "## Currently failing to export to onnx :(\n",
    "# from babl.config import Fitting as FittingArgs\n",
    "# args = FittingArgs()\n",
    "# OnnxExporter(model=predictor, model_name=full_model_name,output_dir=args.model_dir)()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2681: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/nameduser/.local/share/virtualenvs/babl-qoEDH0A2/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:289: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'london'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babl.config import Fitting as FittingArgs\n",
    "args = FittingArgs()\n",
    "OnnxExporter(model=predictor, model_name=full_model_name,output_dir=args.model_dir)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from babl.utils import OnnxExporter, Predictor \n",
    "from babl.config import Data as DataArgs\n",
    "import torch \n",
    "# os.environ['MODEL_NAME']\n",
    "\n",
    "\n",
    "# during distributed training accessing the model is further down the module tree\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() == 1:\n",
    "    model = fitter.trainer.model.model\n",
    "    # fitter.trainer.model\n",
    "    tokenizer = fitter.data_module.tokenizer\n",
    "\n",
    "args = DataArgs()\n",
    "predictor = Predictor(tokenizer=tokenizer, model=model, input_max_len=args.input_max_len)\n",
    "from babl.config import Fitting as FittingArgs\n",
    "args = FittingArgs()\n",
    "OnnxExporter(model=predictor, model_name=full_model_name,output_dir=args.model_dir)()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is the captial of England?\"\n",
    "context= 'I was born 1995'\n",
    "predictor(question, context)\n",
    "\n",
    "\n",
    "from babl.config import Fitting as FittingArgs\n",
    "args = FittingArgs()\n",
    "OnnxExporter(model=predictor, model_name=full_model_name,output_dir=args.model_dir)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from argparse_dataclass import ArgumentParser\n",
    "@dataclass\n",
    "class Options:\n",
    "     x: int = 1\n",
    "     y: int = field(default=2)\n",
    "     z: float = field(default_factory=lambda: 3.14)\n",
    "\n",
    "parser = ArgumentParser(Options)\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "# print (parser.parse_args([]))\n",
    "# Options(x=1, y=2, z=3.14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b in t_dl:\n",
    "#     # print(b)\n",
    "#     m(**b)\n",
    "\n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "y = torch.tensor([[ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100],\n",
    "                  [ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100],\n",
    "                  [ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100],\n",
    "                  [ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100]], dtype=torch.long\n",
    ")\n",
    "y_hat = torch.tensor([[-20.2879,  -9.8936, -13.5965, -40.7275, -40.8642, -40.8486],\n",
    "         [-34.0870,  -3.6627, -14.2458,  -46.1296, -46.3147, -46.2990],\n",
    "         [-30.5974,  -3.4536, -15.5923,  -43.6581, -43.8461, -43.8219],\n",
    "         [-18.1922,  -8.0767, -14.5352,  -45.5706, -45.7357, -45.7194],\n",
    "         [-18.1516,  -8.0787, -14.4750,  -45.4796, -45.6429, -45.6272],\n",
    "         [-18.1262,  -8.1061, -14.4559,  -45.4136, -45.5755, -45.5602],\n",
    "         [-17.2200,  -9.7170, -14.2499,  -38.4455, -38.5326, -38.4609],\n",
    "         [-34.3804,  -6.2359, -13.2374,  -42.5014, -42.6473, -42.5558],\n",
    "         [-27.8060,  -7.1265, -15.4786,  -42.2502, -42.3610, -42.2977],\n",
    "         [-17.2795,  -7.8251, -15.8752,  -44.6078, -44.7242, -44.6339],\n",
    "         [-17.1784,  -7.7900, -15.8198,   -44.4029, -44.5184, -44.4275],\n",
    "         [-17.1213,  -7.7632, -15.7711,   -44.2831, -44.3977, -44.3082]]) \n",
    "\n",
    "num_class= 1321\n",
    "y_hat = torch.stack([y_hat]*num_class, dim=2)\n",
    "\n",
    "y_hat.shape\n",
    "y.shape\n",
    "# y.shape\n",
    "# y_hat.shape\n",
    "y = F.one_hot(y, num_classes=1321)\n",
    "y = y.float()\n",
    "\n",
    "y.shape == y_hat.shape\n",
    "\n",
    "y_hat = F.softmax(y_hat, dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "losses = []\n",
    "for tok in range(y_hat.shape[1]):\n",
    "    print(y[:,tok,:].shape)\n",
    "    print(y_hat[:,tok,:].shape)\n",
    "    loss = F.cross_entropy(y_hat[:,tok,:] , y[:,tok,:])\n",
    "    print(loss)\n",
    "    # loss = F.nll_loss(y_hat[:,tok,:] , y[:,tok,:])\n",
    "    losses.append(loss)\n",
    "\n",
    "\n",
    "torch.tensor(losses).mean()\n",
    "# yx = F.one_hot(y, num_classes=1321)[:,0,:].shape\n",
    "\n",
    "# loss = F.nll_loss(y_hat , y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path_root = Path(\"/home/nameduser/Code/babl/inputs\")\n",
    "\n",
    "data_path_val = data_path_root / \"10k.jsonl\"\n",
    "ds = TextDataset(data_path_val, tokenizer=t, plain_text=True )\n",
    "\n",
    "# from babl.data import T2TDataCollator\n",
    "# from torch.utils.data import DataLoader\n",
    "# t_dl = DataLoader(ds, batch_size=64, shuffle=True, collate_fn=T2TDataCollator())\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "# data_module = TextDataModule(data_path, tokenizer)\n",
    "\n",
    "\n",
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([0,1,1,0,0,1])\n",
    "\n",
    "yh=  torch.tensor([0,1,1,0,1,1])\n",
    "(y == yh).int()\n",
    "\n",
    "\n",
    "torch.prod(torch.tensor(torch.rand((10,10)).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed (1414)\n",
    "\n",
    "t = torch.randn (8, 4)\n",
    "a = t.argmax(1)\n",
    "m = torch.zeros(t.shape).scatter(1, a.unsqueeze(1), 1.0)\n",
    "\n",
    "\n",
    "print ('\\n', t, '\\n\\n', a, '\\n\\n', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list({\"x\": [1, 2, 3, 4]}.values())[0].__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babl-qoEDH0A2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
