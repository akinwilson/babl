{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to pytorch lightning fitting routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorboard\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "VOCAB_SIZE = 32128\n",
    "\n",
    "class Routine(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = 1e-3\n",
    "        self.validation_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        labels,\n",
    "        decoder_attention_mask, \n",
    "    ):\n",
    "        y_hat = self.model(input_ids=input_ids, attention_mask=attention_mask, decoder_attention_mask=decoder_attention_mask, labels=labels)\n",
    "        \n",
    "        # print(f\"forward(): {y_hat=}\")\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # print(f\"keys = {batch.keys()}\")\n",
    "        # print(f\"{batch=}\")\n",
    "        y = batch['labels']\n",
    "        y_hat = self(**batch)\n",
    "        y_onehot = F.one_hot(y, num_classes=VOCAB_SIZE)\n",
    "        y = y_onehot.float()\n",
    "        losses = []\n",
    "        # computing cross-entropy on per-token basis and averaging the loss. \n",
    "        for tok in range(y_hat.logits.shape[1]):\n",
    "            # print(\"Per-token loss cross entropy\")\n",
    "            loss = F.cross_entropy(y_hat.logits[:,tok,:] , y[:,tok,:])\n",
    "            # print(loss)\n",
    "            # loss = F.nll_loss(y_hat[:,tok,:] , y[:,tok,:])\n",
    "            losses.append(loss)\n",
    "\n",
    "        loss  = torch.tensor(losses,  requires_grad=True).mean()\n",
    "        # dummy metrics\n",
    "\n",
    "\n",
    "        # calculating exact matches \n",
    "        y_hat = F.softmax(y_hat.logits, dim=-1)\n",
    "        a = y_hat.argmax(1)\n",
    "        y_hat = torch.zeros(y_hat.shape).scatter(1, a.unsqueeze(1), 1.0)\n",
    "        # y_onehot = F.one_hot(y, num_classes=VOCAB_SIZE)\n",
    "        # y = y_onehot.float()\n",
    "        matches = (y == y_hat).int()\n",
    "        correct = matches.sum()\n",
    "        tot = torch.prod(torch.tensor(matches.shape))\n",
    "\n",
    "\n",
    "\n",
    "        metrics_dict = {\"loss\": loss, \"train_EM\": (correct/tot).item(), \"train_F1\": 0.9}\n",
    "        \n",
    "        print(metrics_dict)\n",
    "        self.training_step_outputs.append(metrics_dict)\n",
    "        return metrics_dict\n",
    "\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        results = {\n",
    "            \"loss\": torch.tensor(\n",
    "                [x[\"loss\"] for x in self.training_step_outputs]\n",
    "            ).mean(),\n",
    "            \"F1\": torch.tensor(\n",
    "                [x[\"train_F1\"] for x in self.training_step_outputs]\n",
    "            ).mean(),\n",
    "            \"EM\": torch.tensor(\n",
    "                [x[\"train_EM\"] for x in self.training_step_outputs]\n",
    "            ).mean(),\n",
    "        }\n",
    "        # self.log(f\"LR\",self.lr, on_epoch=True, prog_bar=True, logger=True)\n",
    "        for k, v in results.items():\n",
    "            self.log(\n",
    "                f\"train_{k}\",\n",
    "                v,\n",
    "                on_epoch=True,\n",
    "                prog_bar=True,\n",
    "                logger=True,\n",
    "                sync_dist=True,\n",
    "            )\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y = batch['labels']\n",
    "        y_hat = self(**batch)\n",
    "        y_onehot = F.one_hot(y, num_classes=VOCAB_SIZE)\n",
    "        y = y_onehot.float()\n",
    "        losses = []\n",
    "        # computing cross-entropy on per-token basis and averaging the loss. \n",
    "        for tok in range(y_hat.logits.shape[1]):\n",
    "            loss = F.cross_entropy(y_hat.logits[:,tok,:] , y[:,tok,:])\n",
    "            # print(loss)\n",
    "            losses.append(loss)\n",
    "        loss  = torch.tensor(losses).mean()\n",
    "\n",
    "\n",
    "\n",
    "        # calculating exact matches \n",
    "        y_hat = F.softmax(y_hat.logits, dim=-1)\n",
    "        a = y_hat.argmax(1)\n",
    "        y_hat = torch.zeros(y_hat.shape).scatter(1, a.unsqueeze(1), 1.0)\n",
    "        matches = (y == y_hat).int()\n",
    "        correct = matches.sum()\n",
    "        tot = torch.prod(torch.tensor(matches.shape))\n",
    "        \n",
    "\n",
    "\n",
    "        # dummy metrics\n",
    "        metrics_dict = {\"val_loss\": loss.item(), \"val_EM\": (correct/tot).item(), \"val_F1\": 0.9}\n",
    "        self.validation_step_outputs.append(metrics_dict)\n",
    "        return metrics_dict\n",
    "\n",
    "\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        results = {\n",
    "            \"loss\": torch.tensor(\n",
    "                [x[\"val_loss\"] for x in self.validation_step_outputs]\n",
    "            ).mean(),\n",
    "            \"EM\": torch.tensor(\n",
    "                [x[\"val_EM\"] for x in self.validation_step_outputs]\n",
    "            ).mean(),\n",
    "            \"F1\": torch.tensor(\n",
    "                [x[\"val_F1\"] for x in self.validation_step_outputs]\n",
    "            ).mean(),\n",
    "        }\n",
    "        for k, v in results.items():\n",
    "            self.log(\n",
    "                f\"val_{k}\", v, on_epoch=True, prog_bar=True, logger=True, sync_dist=True\n",
    "            )\n",
    "            # self.log(f\"val_{k}\", v, on_epoch=True, prog_bar=True) # , logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # x = batch[\"x\"]\n",
    "        \n",
    "        \n",
    "        y = batch[\"labels\"]\n",
    "        y_hat = self(**batch)\n",
    "        \n",
    "        # calculating exact matches \n",
    "        y_hat = F.softmax(y_hat.logits, dim=-1)\n",
    "        a = y_hat.argmax(1)\n",
    "        y_hat = torch.zeros(y_hat.shape).scatter(1, a.unsqueeze(1), 1.0)\n",
    "        y_onehot = F.one_hot(y, num_classes=VOCAB_SIZE)\n",
    "        y = y_onehot.float()\n",
    "        matches = (y == y_hat).int()\n",
    "        correct = matches.sum()\n",
    "        tot = torch.prod(torch.tensor(matches.shape))\n",
    "        \n",
    "        \n",
    "        metrics_dict = {\n",
    "            \"test_EM\": (correct/tot).item(),\n",
    "            \"test_F1\": 0.8,\n",
    "        }\n",
    "        self.test_step_outputs.append(metrics_dict)\n",
    "        return metrics_dict\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        results = {\n",
    "            \"F1\": torch.tensor([x[\"test_EM\"] for x in self.test_step_outputs]).mean(),\n",
    "            \"EM\": torch.tensor([x[\"test_F1\"] for x in self.test_step_outputs]).mean(),\n",
    "        }\n",
    "\n",
    "        for k, v in results.items():\n",
    "            self.log(\n",
    "                f\"test_{k}\",\n",
    "                v,\n",
    "                on_epoch=True,\n",
    "                prog_bar=True,\n",
    "                logger=True,\n",
    "                sync_dist=True,\n",
    "            )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # special scheduler for transformers\n",
    "        optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, self.parameters()),\n",
    "            lr=0.001,  # self.cfg_fitting.learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=0.05,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from babl.data import TextDataset, TextDataModule\n",
    "from babl.utils import CallbackCollection\n",
    "\n",
    "class Fitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        model_name,\n",
    "        data_path=\"../inputs\",\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_name = model_name\n",
    "        self.data_path = data_path\n",
    "\n",
    "        ####################################################################################\n",
    "        @dataclass\n",
    "        class FittingArgs:\n",
    "            es_patience: int = 5\n",
    "            model_dir = Path(\"/home/nameduser/Code/babl/outputs\") / model_name\n",
    "            max_epoch: int = 10\n",
    "            fast_dev_run: bool = False\n",
    "\n",
    "            def __post_init__(self):\n",
    "                self.model_dir.mkdir(parents=True, exist_ok=True)\n",
    "                self.model_dir  =  str(self.model_dir)\n",
    "\n",
    "        ####################################################################################\n",
    "\n",
    "        self.args = FittingArgs()\n",
    "\n",
    "    def setup(self):\n",
    "        data_module = TextDataModule(data_path=self.data_path, tokenizer=self.tokenizer, dev_run=True)\n",
    "\n",
    "        train_loader = data_module.train_dataloader()\n",
    "        val_loader = data_module.val_dataloader()\n",
    "        test_loader = data_module.test_dataloader()\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    def callbacks(self):\n",
    "        # cfg_fitting = self.cfg_fitting\n",
    "        callback_collection = CallbackCollection(self.data_path, self.args)\n",
    "        return callback_collection()\n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=self.args.model_dir,\n",
    "            name=\"lightning_logs\",\n",
    "        )\n",
    "        Model = self.model\n",
    "        # get loaders and datamodule to access input shape\n",
    "        train_loader, val_loader, test_loader = self.setup()\n",
    "        print(\"Created training, validating and test loaders .... \")\n",
    "        # get input shape for onnx exporting\n",
    "        # input_shape = data_module.input_shape\n",
    "        # init model\n",
    "        # kwargs = {}\n",
    "        # model = Model(**kwargs)\n",
    "\n",
    "        # setup training, validating and testing routines for the model\n",
    "        routine = Routine(self.model)\n",
    "\n",
    "        # Init a trainer to execute routine\n",
    "        callback_dict = self.callbacks()\n",
    "        callback_list = [v for (_, v) in callback_dict.items()]\n",
    "        number_devices = os.getenv(\"CUDA_VISIBLE_DEVICES\", \"1,\").split(\",\")\n",
    "        try:\n",
    "            number_devices.remove(\"\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        trainer = Trainer(\n",
    "            accelerator=\"cpu\",\n",
    "            devices=len(number_devices),\n",
    "            # strategy=os.getenv(\"STRATEGY\", \"ddp_notebook\"),\n",
    "            sync_batchnorm=True,\n",
    "            logger=logger,\n",
    "            max_epochs=self.args.max_epoch,\n",
    "            callbacks=callback_list,\n",
    "            num_sanity_val_steps=2,\n",
    "            # resume_from_checkpoint=self.cfg_fitting.resume_from_checkpoint,\n",
    "            gradient_clip_val=1.0,\n",
    "            fast_dev_run=self.args.fast_dev_run,\n",
    "        )\n",
    "\n",
    "        trainer.fit(\n",
    "            routine, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "        )  # ,ckpt_path=PATH)\n",
    "\n",
    "        if self.args.fast_dev_run:\n",
    "            # issue with finding best weights path for in fast dev run using last model weights\n",
    "            model_ckpt_path = callback_dict[\"checkpoint\"].__dict__[\"last_model_path\"]\n",
    "        else:\n",
    "            model_ckpt_path = callback_dict[\"checkpoint\"].__dict__[\"best_model_path\"]\n",
    "\n",
    "        trainer.test(\n",
    "            dataloaders=test_loader,\n",
    "            ckpt_path=model_ckpt_path,\n",
    "        )\n",
    "        # Return the input_shapes and trainer of the model for exporting\n",
    "        return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                       | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M | train\n",
      "-------------------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n",
      "277       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training, validating and test loaders .... \n",
      "Epoch 0:   0%|          | 0/1958 [00:00<?, ?it/s]                          {'loss': tensor(9.9305, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 1/1958 [00:00<30:05,  1.08it/s, v_num=2]{'loss': tensor(9.1113, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 2/1958 [00:01<24:19,  1.34it/s, v_num=2]{'loss': tensor(8.5165, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 3/1958 [00:02<22:32,  1.45it/s, v_num=2]{'loss': tensor(10.7405, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 4/1958 [00:02<21:03,  1.55it/s, v_num=2]{'loss': tensor(9.4112, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 5/1958 [00:03<20:02,  1.62it/s, v_num=2]{'loss': tensor(10.1300, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 6/1958 [00:03<19:26,  1.67it/s, v_num=2]{'loss': tensor(10.2591, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 7/1958 [00:04<18:55,  1.72it/s, v_num=2]{'loss': tensor(10.0273, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 8/1958 [00:04<18:30,  1.76it/s, v_num=2]{'loss': tensor(11.3239, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:   0%|          | 9/1958 [00:05<18:16,  1.78it/s, v_num=2]{'loss': tensor(9.8133, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 10/1958 [00:05<18:02,  1.80it/s, v_num=2]{'loss': tensor(10.1733, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 11/1958 [00:06<18:01,  1.80it/s, v_num=2]{'loss': tensor(9.9493, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 12/1958 [00:06<17:59,  1.80it/s, v_num=2]{'loss': tensor(9.7012, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 13/1958 [00:07<17:47,  1.82it/s, v_num=2]{'loss': tensor(9.6817, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 14/1958 [00:07<17:42,  1.83it/s, v_num=2]{'loss': tensor(10.1776, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 15/1958 [00:08<17:32,  1.85it/s, v_num=2]{'loss': tensor(9.9716, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 16/1958 [00:08<17:23,  1.86it/s, v_num=2]{'loss': tensor(11.9822, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 17/1958 [00:09<17:15,  1.87it/s, v_num=2]{'loss': tensor(10.7085, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 18/1958 [00:09<17:13,  1.88it/s, v_num=2]{'loss': tensor(10.3042, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 19/1958 [00:10<17:13,  1.88it/s, v_num=2]{'loss': tensor(9.6240, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 20/1958 [00:10<17:10,  1.88it/s, v_num=2]{'loss': tensor(10.4759, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 21/1958 [00:11<17:04,  1.89it/s, v_num=2]{'loss': tensor(10.2233, grad_fn=<MeanBackward0>), 'train_EM': 0.9843552112579346, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 22/1958 [00:11<16:58,  1.90it/s, v_num=2]{'loss': tensor(10.9897, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 23/1958 [00:12<16:53,  1.91it/s, v_num=2]{'loss': tensor(11.2364, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|          | 24/1958 [00:12<16:49,  1.91it/s, v_num=2]{'loss': tensor(10.6530, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|▏         | 25/1958 [00:12<16:44,  1.92it/s, v_num=2]{'loss': tensor(8.5614, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|▏         | 26/1958 [00:13<16:38,  1.93it/s, v_num=2]{'loss': tensor(10.9174, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|▏         | 27/1958 [00:13<16:37,  1.93it/s, v_num=2]{'loss': tensor(10.6494, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|▏         | 28/1958 [00:14<16:36,  1.94it/s, v_num=2]{'loss': tensor(10.6732, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   1%|▏         | 29/1958 [00:15<16:40,  1.93it/s, v_num=2]{'loss': tensor(8.4230, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 30/1958 [00:15<16:40,  1.93it/s, v_num=2]{'loss': tensor(10.2762, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 31/1958 [00:16<16:36,  1.93it/s, v_num=2]{'loss': tensor(10.9907, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 32/1958 [00:16<16:31,  1.94it/s, v_num=2]{'loss': tensor(9.0255, grad_fn=<MeanBackward0>), 'train_EM': 0.9843554496765137, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 33/1958 [00:16<16:28,  1.95it/s, v_num=2]{'loss': tensor(10.4235, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 34/1958 [00:17<16:24,  1.95it/s, v_num=2]{'loss': tensor(10.9784, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 35/1958 [00:17<16:20,  1.96it/s, v_num=2]{'loss': tensor(11.4287, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 36/1958 [00:18<16:17,  1.97it/s, v_num=2]{'loss': tensor(9.7667, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 37/1958 [00:18<16:14,  1.97it/s, v_num=2]{'loss': tensor(9.3243, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 38/1958 [00:19<16:11,  1.98it/s, v_num=2]{'loss': tensor(9.4439, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 39/1958 [00:19<16:11,  1.98it/s, v_num=2]{'loss': tensor(8.5330, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 40/1958 [00:20<16:09,  1.98it/s, v_num=2]{'loss': tensor(8.5233, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 41/1958 [00:20<16:07,  1.98it/s, v_num=2]{'loss': tensor(9.8070, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 42/1958 [00:21<16:04,  1.99it/s, v_num=2]{'loss': tensor(9.2767, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 43/1958 [00:21<16:02,  1.99it/s, v_num=2]{'loss': tensor(8.7098, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 44/1958 [00:22<16:01,  1.99it/s, v_num=2]{'loss': tensor(8.1651, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 45/1958 [00:22<15:59,  1.99it/s, v_num=2]{'loss': tensor(9.5546, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 46/1958 [00:23<15:59,  1.99it/s, v_num=2]{'loss': tensor(9.9370, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 47/1958 [00:23<15:57,  1.99it/s, v_num=2]{'loss': tensor(9.6743, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   2%|▏         | 48/1958 [00:24<15:59,  1.99it/s, v_num=2]{'loss': tensor(8.4473, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 49/1958 [00:24<15:57,  1.99it/s, v_num=2]{'loss': tensor(10.2315, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 50/1958 [00:25<16:00,  1.99it/s, v_num=2]{'loss': tensor(9.5690, grad_fn=<MeanBackward0>), 'train_EM': 0.9843592047691345, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 51/1958 [00:25<15:58,  1.99it/s, v_num=2]{'loss': tensor(10.5953, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 52/1958 [00:26<15:56,  1.99it/s, v_num=2]{'loss': tensor(10.3249, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 53/1958 [00:26<15:58,  1.99it/s, v_num=2]{'loss': tensor(7.8086, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 54/1958 [00:27<15:59,  1.98it/s, v_num=2]{'loss': tensor(9.6348, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 55/1958 [00:27<15:58,  1.99it/s, v_num=2]{'loss': tensor(9.4360, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 56/1958 [00:28<15:58,  1.99it/s, v_num=2]{'loss': tensor(10.6552, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 57/1958 [00:28<15:56,  1.99it/s, v_num=2]{'loss': tensor(8.9249, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 58/1958 [00:29<15:54,  1.99it/s, v_num=2]{'loss': tensor(10.7502, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 59/1958 [00:29<15:53,  1.99it/s, v_num=2]{'loss': tensor(8.4507, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 60/1958 [00:30<15:53,  1.99it/s, v_num=2]{'loss': tensor(10.7587, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 61/1958 [00:30<15:51,  1.99it/s, v_num=2]{'loss': tensor(10.3818, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 62/1958 [00:31<15:49,  2.00it/s, v_num=2]{'loss': tensor(9.5524, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 63/1958 [00:31<15:47,  2.00it/s, v_num=2]{'loss': tensor(8.5722, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 64/1958 [00:32<15:47,  2.00it/s, v_num=2]{'loss': tensor(9.0738, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 65/1958 [00:32<15:45,  2.00it/s, v_num=2]{'loss': tensor(8.2771, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 66/1958 [00:32<15:44,  2.00it/s, v_num=2]{'loss': tensor(10.9962, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 67/1958 [00:33<15:42,  2.01it/s, v_num=2]{'loss': tensor(10.5916, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   3%|▎         | 68/1958 [00:33<15:42,  2.00it/s, v_num=2]{'loss': tensor(11.9022, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▎         | 69/1958 [00:34<15:41,  2.01it/s, v_num=2]{'loss': tensor(11.3712, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▎         | 70/1958 [00:34<15:41,  2.01it/s, v_num=2]{'loss': tensor(10.1887, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▎         | 71/1958 [00:35<15:40,  2.01it/s, v_num=2]{'loss': tensor(9.9318, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▎         | 72/1958 [00:35<15:39,  2.01it/s, v_num=2]{'loss': tensor(10.3621, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▎         | 73/1958 [00:36<15:37,  2.01it/s, v_num=2]{'loss': tensor(10.7901, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 74/1958 [00:36<15:36,  2.01it/s, v_num=2]{'loss': tensor(10.2087, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 75/1958 [00:37<15:35,  2.01it/s, v_num=2]{'loss': tensor(9.5032, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 76/1958 [00:37<15:34,  2.01it/s, v_num=2]{'loss': tensor(9.4499, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 77/1958 [00:38<15:33,  2.02it/s, v_num=2]{'loss': tensor(10.3075, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 78/1958 [00:38<15:32,  2.02it/s, v_num=2]{'loss': tensor(10.2607, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 79/1958 [00:39<15:31,  2.02it/s, v_num=2]{'loss': tensor(10.7611, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 80/1958 [00:39<15:30,  2.02it/s, v_num=2]{'loss': tensor(8.4336, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 81/1958 [00:40<15:29,  2.02it/s, v_num=2]{'loss': tensor(9.2709, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 82/1958 [00:40<15:28,  2.02it/s, v_num=2]{'loss': tensor(8.9928, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 83/1958 [00:41<15:27,  2.02it/s, v_num=2]{'loss': tensor(11.3676, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 84/1958 [00:41<15:27,  2.02it/s, v_num=2]{'loss': tensor(8.9162, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 85/1958 [00:42<15:26,  2.02it/s, v_num=2]{'loss': tensor(10.1376, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 86/1958 [00:42<15:25,  2.02it/s, v_num=2]{'loss': tensor(11.5463, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 87/1958 [00:42<15:24,  2.02it/s, v_num=2]{'loss': tensor(9.9960, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   4%|▍         | 88/1958 [00:43<15:23,  2.03it/s, v_num=2]{'loss': tensor(10.6774, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 89/1958 [00:43<15:22,  2.03it/s, v_num=2]{'loss': tensor(10.9971, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 90/1958 [00:44<15:21,  2.03it/s, v_num=2]{'loss': tensor(9.0717, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 91/1958 [00:44<15:21,  2.03it/s, v_num=2]{'loss': tensor(10.1300, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 92/1958 [00:45<15:20,  2.03it/s, v_num=2]{'loss': tensor(10.0477, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 93/1958 [00:45<15:19,  2.03it/s, v_num=2]{'loss': tensor(9.9326, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 94/1958 [00:46<15:19,  2.03it/s, v_num=2]{'loss': tensor(9.6488, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 95/1958 [00:46<15:18,  2.03it/s, v_num=2]{'loss': tensor(10.9421, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 96/1958 [00:47<15:17,  2.03it/s, v_num=2]{'loss': tensor(11.0387, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▍         | 97/1958 [00:47<15:16,  2.03it/s, v_num=2]{'loss': tensor(9.7940, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 98/1958 [00:48<15:15,  2.03it/s, v_num=2]{'loss': tensor(10.9423, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 99/1958 [00:48<15:14,  2.03it/s, v_num=2]{'loss': tensor(8.6391, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 100/1958 [00:49<15:13,  2.03it/s, v_num=2]{'loss': tensor(12.4625, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 101/1958 [00:49<15:12,  2.03it/s, v_num=2]{'loss': tensor(8.9765, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 102/1958 [00:50<15:12,  2.03it/s, v_num=2]{'loss': tensor(9.2587, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 103/1958 [00:50<15:12,  2.03it/s, v_num=2]{'loss': tensor(10.1485, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 104/1958 [00:51<15:12,  2.03it/s, v_num=2]{'loss': tensor(8.2675, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 105/1958 [00:51<15:11,  2.03it/s, v_num=2]{'loss': tensor(10.5944, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 106/1958 [00:52<15:10,  2.03it/s, v_num=2]{'loss': tensor(9.3919, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   5%|▌         | 107/1958 [00:52<15:09,  2.04it/s, v_num=2]{'loss': tensor(10.8271, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 108/1958 [00:53<15:08,  2.04it/s, v_num=2]{'loss': tensor(10.1842, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 109/1958 [00:53<15:08,  2.04it/s, v_num=2]{'loss': tensor(10.8288, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 110/1958 [00:54<15:09,  2.03it/s, v_num=2]{'loss': tensor(11.1135, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 111/1958 [00:54<15:11,  2.03it/s, v_num=2]{'loss': tensor(9.6421, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 112/1958 [00:55<15:12,  2.02it/s, v_num=2]{'loss': tensor(11.2866, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 113/1958 [00:55<15:12,  2.02it/s, v_num=2]{'loss': tensor(7.1163, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 114/1958 [00:56<15:11,  2.02it/s, v_num=2]{'loss': tensor(11.4875, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 115/1958 [00:56<15:12,  2.02it/s, v_num=2]{'loss': tensor(10.0237, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 116/1958 [00:57<15:13,  2.02it/s, v_num=2]{'loss': tensor(11.9218, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 117/1958 [00:58<15:14,  2.01it/s, v_num=2]{'loss': tensor(8.4447, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 118/1958 [00:58<15:14,  2.01it/s, v_num=2]{'loss': tensor(8.7895, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 119/1958 [00:59<15:15,  2.01it/s, v_num=2]{'loss': tensor(10.6576, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 120/1958 [00:59<15:14,  2.01it/s, v_num=2]{'loss': tensor(10.0566, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 121/1958 [01:00<15:13,  2.01it/s, v_num=2]{'loss': tensor(9.3780, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▌         | 122/1958 [01:00<15:13,  2.01it/s, v_num=2]{'loss': tensor(10.1276, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▋         | 123/1958 [01:01<15:13,  2.01it/s, v_num=2]{'loss': tensor(10.1282, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▋         | 124/1958 [01:01<15:14,  2.01it/s, v_num=2]{'loss': tensor(10.8567, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▋         | 125/1958 [01:02<15:15,  2.00it/s, v_num=2]{'loss': tensor(9.8018, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▋         | 126/1958 [01:02<15:14,  2.00it/s, v_num=2]{'loss': tensor(10.6669, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   6%|▋         | 127/1958 [01:03<15:13,  2.00it/s, v_num=2]{'loss': tensor(10.3063, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 128/1958 [01:03<15:12,  2.00it/s, v_num=2]{'loss': tensor(9.2657, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 129/1958 [01:04<15:13,  2.00it/s, v_num=2]{'loss': tensor(9.0297, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 130/1958 [01:04<15:13,  2.00it/s, v_num=2]{'loss': tensor(8.8787, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 131/1958 [01:05<15:12,  2.00it/s, v_num=2]{'loss': tensor(9.2439, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 132/1958 [01:05<15:12,  2.00it/s, v_num=2]{'loss': tensor(9.2232, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 133/1958 [01:06<15:13,  2.00it/s, v_num=2]{'loss': tensor(9.5080, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 134/1958 [01:07<15:12,  2.00it/s, v_num=2]{'loss': tensor(10.4700, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 135/1958 [01:07<15:12,  2.00it/s, v_num=2]{'loss': tensor(11.5231, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 136/1958 [01:08<15:11,  2.00it/s, v_num=2]{'loss': tensor(8.6935, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 137/1958 [01:08<15:10,  2.00it/s, v_num=2]{'loss': tensor(10.7250, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 138/1958 [01:08<15:09,  2.00it/s, v_num=2]{'loss': tensor(10.3736, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 139/1958 [01:09<15:08,  2.00it/s, v_num=2]{'loss': tensor(9.8540, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 140/1958 [01:10<15:09,  2.00it/s, v_num=2]{'loss': tensor(10.3136, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 141/1958 [01:10<15:10,  2.00it/s, v_num=2]{'loss': tensor(10.8411, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 142/1958 [01:11<15:09,  2.00it/s, v_num=2]{'loss': tensor(8.8959, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 143/1958 [01:11<15:09,  2.00it/s, v_num=2]{'loss': tensor(11.1846, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 144/1958 [01:12<15:08,  2.00it/s, v_num=2]{'loss': tensor(11.5829, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 145/1958 [01:12<15:07,  2.00it/s, v_num=2]{'loss': tensor(9.5231, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   7%|▋         | 146/1958 [01:13<15:06,  2.00it/s, v_num=2]{'loss': tensor(11.3143, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 147/1958 [01:13<15:06,  2.00it/s, v_num=2]{'loss': tensor(8.3578, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 148/1958 [01:14<15:07,  1.99it/s, v_num=2]{'loss': tensor(8.3614, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 149/1958 [01:14<15:07,  1.99it/s, v_num=2]{'loss': tensor(11.1877, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 150/1958 [01:15<15:07,  1.99it/s, v_num=2]{'loss': tensor(9.9046, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 151/1958 [01:15<15:08,  1.99it/s, v_num=2]{'loss': tensor(10.3673, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 152/1958 [01:16<15:07,  1.99it/s, v_num=2]{'loss': tensor(10.0429, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 153/1958 [01:16<15:06,  1.99it/s, v_num=2]{'loss': tensor(10.1885, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 154/1958 [01:17<15:06,  1.99it/s, v_num=2]{'loss': tensor(9.0057, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 155/1958 [01:17<15:06,  1.99it/s, v_num=2]{'loss': tensor(8.6659, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 156/1958 [01:18<15:07,  1.99it/s, v_num=2]{'loss': tensor(11.1352, grad_fn=<MeanBackward0>), 'train_EM': 0.9843550324440002, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 157/1958 [01:19<15:07,  1.98it/s, v_num=2]{'loss': tensor(8.7103, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 158/1958 [01:19<15:08,  1.98it/s, v_num=2]{'loss': tensor(10.0485, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 159/1958 [01:20<15:08,  1.98it/s, v_num=2]{'loss': tensor(11.1083, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 160/1958 [01:20<15:09,  1.98it/s, v_num=2]{'loss': tensor(12.1903, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 161/1958 [01:21<15:10,  1.97it/s, v_num=2]{'loss': tensor(9.0961, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 162/1958 [01:22<15:10,  1.97it/s, v_num=2]{'loss': tensor(10.0687, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 163/1958 [01:22<15:11,  1.97it/s, v_num=2]{'loss': tensor(10.0369, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 164/1958 [01:23<15:11,  1.97it/s, v_num=2]{'loss': tensor(9.6573, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 165/1958 [01:23<15:12,  1.96it/s, v_num=2]{'loss': tensor(10.1593, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:   8%|▊         | 166/1958 [01:24<15:12,  1.96it/s, v_num=2]{'loss': tensor(9.0155, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▊         | 167/1958 [01:25<15:11,  1.96it/s, v_num=2]{'loss': tensor(10.6263, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▊         | 168/1958 [01:25<15:10,  1.97it/s, v_num=2]{'loss': tensor(9.7777, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▊         | 169/1958 [01:26<15:10,  1.96it/s, v_num=2]{'loss': tensor(10.8695, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▊         | 170/1958 [01:26<15:09,  1.97it/s, v_num=2]{'loss': tensor(10.1419, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▊         | 171/1958 [01:26<15:08,  1.97it/s, v_num=2]{'loss': tensor(8.9982, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 172/1958 [01:27<15:07,  1.97it/s, v_num=2]{'loss': tensor(10.4461, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 173/1958 [01:27<15:07,  1.97it/s, v_num=2]{'loss': tensor(9.8655, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 174/1958 [01:28<15:06,  1.97it/s, v_num=2]{'loss': tensor(8.3293, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 175/1958 [01:28<15:05,  1.97it/s, v_num=2]{'loss': tensor(11.2365, grad_fn=<MeanBackward0>), 'train_EM': 0.9843550324440002, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 176/1958 [01:29<15:04,  1.97it/s, v_num=2]{'loss': tensor(10.2164, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 177/1958 [01:29<15:03,  1.97it/s, v_num=2]{'loss': tensor(10.6534, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 178/1958 [01:30<15:02,  1.97it/s, v_num=2]{'loss': tensor(8.3366, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 179/1958 [01:30<15:02,  1.97it/s, v_num=2]{'loss': tensor(10.0176, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 180/1958 [01:31<15:01,  1.97it/s, v_num=2]{'loss': tensor(11.1543, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 181/1958 [01:31<15:00,  1.97it/s, v_num=2]{'loss': tensor(10.1331, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 182/1958 [01:32<14:59,  1.97it/s, v_num=2]{'loss': tensor(8.8006, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 183/1958 [01:32<14:58,  1.98it/s, v_num=2]{'loss': tensor(10.1384, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 184/1958 [01:33<14:57,  1.98it/s, v_num=2]{'loss': tensor(9.4766, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 185/1958 [01:33<14:57,  1.98it/s, v_num=2]{'loss': tensor(7.5506, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:   9%|▉         | 186/1958 [01:34<14:56,  1.98it/s, v_num=2]{'loss': tensor(9.2324, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 187/1958 [01:34<14:55,  1.98it/s, v_num=2]{'loss': tensor(9.9176, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 188/1958 [01:35<14:54,  1.98it/s, v_num=2]{'loss': tensor(10.8488, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 189/1958 [01:35<14:53,  1.98it/s, v_num=2]{'loss': tensor(11.2824, grad_fn=<MeanBackward0>), 'train_EM': 0.9843553304672241, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 190/1958 [01:36<14:53,  1.98it/s, v_num=2]{'loss': tensor(10.8005, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 191/1958 [01:36<14:52,  1.98it/s, v_num=2]{'loss': tensor(10.9157, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 192/1958 [01:36<14:52,  1.98it/s, v_num=2]{'loss': tensor(8.6450, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 193/1958 [01:37<14:52,  1.98it/s, v_num=2]{'loss': tensor(10.4522, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 194/1958 [01:38<14:51,  1.98it/s, v_num=2]{'loss': tensor(9.5532, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|▉         | 195/1958 [01:38<14:50,  1.98it/s, v_num=2]{'loss': tensor(10.0907, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 196/1958 [01:38<14:49,  1.98it/s, v_num=2]{'loss': tensor(10.0830, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 197/1958 [01:39<14:48,  1.98it/s, v_num=2]{'loss': tensor(11.0082, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 198/1958 [01:39<14:48,  1.98it/s, v_num=2]{'loss': tensor(10.2430, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 199/1958 [01:40<14:48,  1.98it/s, v_num=2]{'loss': tensor(9.9330, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 200/1958 [01:40<14:47,  1.98it/s, v_num=2]{'loss': tensor(8.0846, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 201/1958 [01:41<14:46,  1.98it/s, v_num=2]{'loss': tensor(9.1844, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 202/1958 [01:41<14:45,  1.98it/s, v_num=2]{'loss': tensor(11.2319, grad_fn=<MeanBackward0>), 'train_EM': 0.9843553304672241, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 203/1958 [01:42<14:45,  1.98it/s, v_num=2]{'loss': tensor(9.1204, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 204/1958 [01:42<14:44,  1.98it/s, v_num=2]{'loss': tensor(12.6586, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  10%|█         | 205/1958 [01:43<14:43,  1.98it/s, v_num=2]{'loss': tensor(8.7723, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 206/1958 [01:43<14:43,  1.98it/s, v_num=2]{'loss': tensor(10.4307, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 207/1958 [01:44<14:42,  1.98it/s, v_num=2]{'loss': tensor(10.9051, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 208/1958 [01:44<14:42,  1.98it/s, v_num=2]{'loss': tensor(9.5897, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 209/1958 [01:45<14:41,  1.98it/s, v_num=2]{'loss': tensor(9.6612, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 210/1958 [01:45<14:41,  1.98it/s, v_num=2]{'loss': tensor(10.5594, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 211/1958 [01:46<14:40,  1.98it/s, v_num=2]{'loss': tensor(9.8507, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 212/1958 [01:46<14:39,  1.98it/s, v_num=2]{'loss': tensor(10.7380, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 213/1958 [01:47<14:38,  1.99it/s, v_num=2]{'loss': tensor(9.6148, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 214/1958 [01:47<14:38,  1.99it/s, v_num=2]{'loss': tensor(10.1610, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 215/1958 [01:48<14:37,  1.99it/s, v_num=2]{'loss': tensor(10.9679, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 216/1958 [01:48<14:37,  1.99it/s, v_num=2]{'loss': tensor(8.9912, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 217/1958 [01:49<14:37,  1.99it/s, v_num=2]{'loss': tensor(10.5583, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 218/1958 [01:49<14:37,  1.98it/s, v_num=2]{'loss': tensor(9.9870, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 219/1958 [01:50<14:37,  1.98it/s, v_num=2]{'loss': tensor(11.6805, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█         | 220/1958 [01:51<14:37,  1.98it/s, v_num=2]{'loss': tensor(11.4705, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█▏        | 221/1958 [01:51<14:36,  1.98it/s, v_num=2]{'loss': tensor(10.0368, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█▏        | 222/1958 [01:52<14:35,  1.98it/s, v_num=2]{'loss': tensor(9.4192, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█▏        | 223/1958 [01:52<14:35,  1.98it/s, v_num=2]{'loss': tensor(9.8731, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█▏        | 224/1958 [01:53<14:34,  1.98it/s, v_num=2]{'loss': tensor(10.4752, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  11%|█▏        | 225/1958 [01:53<14:33,  1.98it/s, v_num=2]{'loss': tensor(9.1857, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 226/1958 [01:53<14:33,  1.98it/s, v_num=2]{'loss': tensor(9.8739, grad_fn=<MeanBackward0>), 'train_EM': 0.9843554496765137, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 227/1958 [01:54<14:32,  1.98it/s, v_num=2]{'loss': tensor(10.8235, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 228/1958 [01:54<14:32,  1.98it/s, v_num=2]{'loss': tensor(11.1119, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 229/1958 [01:55<14:31,  1.98it/s, v_num=2]{'loss': tensor(9.2285, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 230/1958 [01:55<14:30,  1.98it/s, v_num=2]{'loss': tensor(10.1416, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 231/1958 [01:56<14:29,  1.99it/s, v_num=2]{'loss': tensor(10.1082, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 232/1958 [01:56<14:29,  1.99it/s, v_num=2]{'loss': tensor(9.9712, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 233/1958 [01:57<14:28,  1.99it/s, v_num=2]{'loss': tensor(13.0171, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 234/1958 [01:57<14:27,  1.99it/s, v_num=2]{'loss': tensor(10.5179, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 235/1958 [01:58<14:27,  1.99it/s, v_num=2]{'loss': tensor(10.4748, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 236/1958 [01:58<14:27,  1.98it/s, v_num=2]{'loss': tensor(8.6958, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 237/1958 [01:59<14:28,  1.98it/s, v_num=2]{'loss': tensor(9.6769, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 238/1958 [02:00<14:27,  1.98it/s, v_num=2]{'loss': tensor(10.8843, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 239/1958 [02:00<14:27,  1.98it/s, v_num=2]{'loss': tensor(9.7751, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 240/1958 [02:01<14:26,  1.98it/s, v_num=2]{'loss': tensor(10.7468, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 241/1958 [02:01<14:25,  1.98it/s, v_num=2]{'loss': tensor(9.7610, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 242/1958 [02:01<14:25,  1.98it/s, v_num=2]{'loss': tensor(10.4036, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 243/1958 [02:02<14:24,  1.98it/s, v_num=2]{'loss': tensor(10.6631, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  12%|█▏        | 244/1958 [02:02<14:23,  1.98it/s, v_num=2]{'loss': tensor(9.1962, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 245/1958 [02:03<14:23,  1.98it/s, v_num=2]{'loss': tensor(9.9080, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 246/1958 [02:04<14:23,  1.98it/s, v_num=2]{'loss': tensor(9.6665, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 247/1958 [02:04<14:23,  1.98it/s, v_num=2]{'loss': tensor(9.4692, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 248/1958 [02:05<14:23,  1.98it/s, v_num=2]{'loss': tensor(9.4548, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 249/1958 [02:05<14:24,  1.98it/s, v_num=2]{'loss': tensor(10.5913, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 250/1958 [02:06<14:24,  1.97it/s, v_num=2]{'loss': tensor(8.7327, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 251/1958 [02:07<14:25,  1.97it/s, v_num=2]{'loss': tensor(9.8101, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 252/1958 [02:07<14:24,  1.97it/s, v_num=2]{'loss': tensor(9.6033, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 253/1958 [02:08<14:24,  1.97it/s, v_num=2]{'loss': tensor(10.0216, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 254/1958 [02:08<14:23,  1.97it/s, v_num=2]{'loss': tensor(9.4888, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 255/1958 [02:09<14:22,  1.97it/s, v_num=2]{'loss': tensor(9.2839, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 256/1958 [02:09<14:22,  1.97it/s, v_num=2]{'loss': tensor(11.6617, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 257/1958 [02:10<14:22,  1.97it/s, v_num=2]{'loss': tensor(10.2735, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 258/1958 [02:10<14:22,  1.97it/s, v_num=2]{'loss': tensor(8.7343, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 259/1958 [02:11<14:21,  1.97it/s, v_num=2]{'loss': tensor(9.4961, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 260/1958 [02:11<14:21,  1.97it/s, v_num=2]{'loss': tensor(9.9244, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 261/1958 [02:12<14:21,  1.97it/s, v_num=2]{'loss': tensor(11.1776, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 262/1958 [02:13<14:21,  1.97it/s, v_num=2]{'loss': tensor(10.1054, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 263/1958 [02:13<14:20,  1.97it/s, v_num=2]{'loss': tensor(10.3617, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  13%|█▎        | 264/1958 [02:13<14:19,  1.97it/s, v_num=2]{'loss': tensor(10.3544, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▎        | 265/1958 [02:14<14:19,  1.97it/s, v_num=2]{'loss': tensor(10.3644, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▎        | 266/1958 [02:15<14:19,  1.97it/s, v_num=2]{'loss': tensor(10.3119, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▎        | 267/1958 [02:15<14:18,  1.97it/s, v_num=2]{'loss': tensor(11.0049, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▎        | 268/1958 [02:16<14:18,  1.97it/s, v_num=2]{'loss': tensor(11.8477, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▎        | 269/1958 [02:16<14:17,  1.97it/s, v_num=2]{'loss': tensor(10.4225, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 270/1958 [02:17<14:17,  1.97it/s, v_num=2]{'loss': tensor(11.1845, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 271/1958 [02:17<14:16,  1.97it/s, v_num=2]{'loss': tensor(11.1603, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 272/1958 [02:18<14:16,  1.97it/s, v_num=2]{'loss': tensor(9.8223, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 273/1958 [02:18<14:15,  1.97it/s, v_num=2]{'loss': tensor(11.0991, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 274/1958 [02:19<14:15,  1.97it/s, v_num=2]{'loss': tensor(10.3103, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 275/1958 [02:19<14:15,  1.97it/s, v_num=2]{'loss': tensor(10.1110, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 276/1958 [02:20<14:15,  1.97it/s, v_num=2]{'loss': tensor(9.8816, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 277/1958 [02:20<14:14,  1.97it/s, v_num=2]{'loss': tensor(9.3277, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 278/1958 [02:21<14:14,  1.97it/s, v_num=2]{'loss': tensor(8.8336, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 279/1958 [02:22<14:14,  1.96it/s, v_num=2]{'loss': tensor(9.9982, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 280/1958 [02:22<14:14,  1.96it/s, v_num=2]{'loss': tensor(9.6274, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 281/1958 [02:23<14:14,  1.96it/s, v_num=2]{'loss': tensor(10.5672, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 282/1958 [02:23<14:14,  1.96it/s, v_num=2]{'loss': tensor(10.6807, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  14%|█▍        | 283/1958 [02:24<14:13,  1.96it/s, v_num=2]{'loss': tensor(10.1438, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 284/1958 [02:24<14:13,  1.96it/s, v_num=2]{'loss': tensor(9.5820, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 285/1958 [02:25<14:13,  1.96it/s, v_num=2]{'loss': tensor(10.0822, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 286/1958 [02:25<14:13,  1.96it/s, v_num=2]{'loss': tensor(11.2123, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 287/1958 [02:26<14:12,  1.96it/s, v_num=2]{'loss': tensor(10.0834, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 288/1958 [02:27<14:12,  1.96it/s, v_num=2]{'loss': tensor(10.4262, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 289/1958 [02:27<14:12,  1.96it/s, v_num=2]{'loss': tensor(11.1697, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 290/1958 [02:28<14:12,  1.96it/s, v_num=2]{'loss': tensor(11.1519, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 291/1958 [02:28<14:12,  1.96it/s, v_num=2]{'loss': tensor(9.5557, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 292/1958 [02:29<14:11,  1.96it/s, v_num=2]{'loss': tensor(8.6598, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▍        | 293/1958 [02:29<14:11,  1.95it/s, v_num=2]{'loss': tensor(8.6575, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 294/1958 [02:30<14:11,  1.95it/s, v_num=2]{'loss': tensor(10.0080, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 295/1958 [02:30<14:10,  1.95it/s, v_num=2]{'loss': tensor(10.5195, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 296/1958 [02:31<14:09,  1.96it/s, v_num=2]{'loss': tensor(9.5190, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 297/1958 [02:32<14:10,  1.95it/s, v_num=2]{'loss': tensor(11.0686, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 298/1958 [02:32<14:10,  1.95it/s, v_num=2]{'loss': tensor(8.9942, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 299/1958 [02:33<14:10,  1.95it/s, v_num=2]{'loss': tensor(9.8712, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 300/1958 [02:33<14:10,  1.95it/s, v_num=2]{'loss': tensor(11.0532, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 301/1958 [02:34<14:10,  1.95it/s, v_num=2]{'loss': tensor(9.0079, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 302/1958 [02:35<14:10,  1.95it/s, v_num=2]{'loss': tensor(9.8543, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  15%|█▌        | 303/1958 [02:35<14:09,  1.95it/s, v_num=2]{'loss': tensor(10.0093, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 304/1958 [02:36<14:08,  1.95it/s, v_num=2]{'loss': tensor(9.6850, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 305/1958 [02:36<14:08,  1.95it/s, v_num=2]{'loss': tensor(9.2480, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 306/1958 [02:36<14:07,  1.95it/s, v_num=2]{'loss': tensor(10.1691, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 307/1958 [02:37<14:06,  1.95it/s, v_num=2]{'loss': tensor(9.4554, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 308/1958 [02:37<14:06,  1.95it/s, v_num=2]{'loss': tensor(9.6821, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 309/1958 [02:38<14:06,  1.95it/s, v_num=2]{'loss': tensor(11.3099, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 310/1958 [02:39<14:06,  1.95it/s, v_num=2]{'loss': tensor(9.7347, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 311/1958 [02:39<14:06,  1.94it/s, v_num=2]{'loss': tensor(10.4487, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 312/1958 [02:40<14:06,  1.95it/s, v_num=2]{'loss': tensor(9.2248, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 313/1958 [02:40<14:06,  1.94it/s, v_num=2]{'loss': tensor(9.8315, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 314/1958 [02:41<14:05,  1.94it/s, v_num=2]{'loss': tensor(9.5279, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 315/1958 [02:42<14:05,  1.94it/s, v_num=2]{'loss': tensor(9.6915, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 316/1958 [02:42<14:04,  1.94it/s, v_num=2]{'loss': tensor(11.5700, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 317/1958 [02:42<14:03,  1.94it/s, v_num=2]{'loss': tensor(10.0908, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▌        | 318/1958 [02:43<14:02,  1.95it/s, v_num=2]{'loss': tensor(10.2258, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▋        | 319/1958 [02:43<14:02,  1.95it/s, v_num=2]{'loss': tensor(8.6360, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▋        | 320/1958 [02:44<14:01,  1.95it/s, v_num=2]{'loss': tensor(10.6466, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▋        | 321/1958 [02:44<14:00,  1.95it/s, v_num=2]{'loss': tensor(9.4791, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▋        | 322/1958 [02:45<13:59,  1.95it/s, v_num=2]{'loss': tensor(10.1644, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  16%|█▋        | 323/1958 [02:45<13:58,  1.95it/s, v_num=2]{'loss': tensor(9.2224, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 324/1958 [02:46<13:57,  1.95it/s, v_num=2]{'loss': tensor(8.7816, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 325/1958 [02:46<13:57,  1.95it/s, v_num=2]{'loss': tensor(9.5547, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 326/1958 [02:47<13:56,  1.95it/s, v_num=2]{'loss': tensor(10.1664, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 327/1958 [02:47<13:55,  1.95it/s, v_num=2]{'loss': tensor(10.6192, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 328/1958 [02:48<13:55,  1.95it/s, v_num=2]{'loss': tensor(10.1406, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 329/1958 [02:48<13:54,  1.95it/s, v_num=2]{'loss': tensor(10.4647, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 330/1958 [02:48<13:53,  1.95it/s, v_num=2]{'loss': tensor(10.5969, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 331/1958 [02:49<13:53,  1.95it/s, v_num=2]{'loss': tensor(7.8639, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 332/1958 [02:50<13:53,  1.95it/s, v_num=2]{'loss': tensor(10.0618, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 333/1958 [02:50<13:53,  1.95it/s, v_num=2]{'loss': tensor(11.3244, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 334/1958 [02:51<13:52,  1.95it/s, v_num=2]{'loss': tensor(9.9636, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 335/1958 [02:51<13:52,  1.95it/s, v_num=2]{'loss': tensor(11.8660, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 336/1958 [02:52<13:52,  1.95it/s, v_num=2]{'loss': tensor(9.7840, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 337/1958 [02:53<13:52,  1.95it/s, v_num=2]{'loss': tensor(10.5750, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 338/1958 [02:53<13:51,  1.95it/s, v_num=2]{'loss': tensor(11.5694, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 339/1958 [02:53<13:50,  1.95it/s, v_num=2]{'loss': tensor(9.4435, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 340/1958 [02:54<13:50,  1.95it/s, v_num=2]{'loss': tensor(9.8552, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 341/1958 [02:54<13:49,  1.95it/s, v_num=2]{'loss': tensor(8.3035, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  17%|█▋        | 342/1958 [02:55<13:49,  1.95it/s, v_num=2]{'loss': tensor(10.5359, grad_fn=<MeanBackward0>), 'train_EM': 0.9843554496765137, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 343/1958 [02:55<13:48,  1.95it/s, v_num=2]{'loss': tensor(9.9818, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 344/1958 [02:56<13:47,  1.95it/s, v_num=2]{'loss': tensor(9.5765, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 345/1958 [02:56<13:47,  1.95it/s, v_num=2]{'loss': tensor(10.3619, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 346/1958 [02:57<13:46,  1.95it/s, v_num=2]{'loss': tensor(10.6086, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 347/1958 [02:57<13:45,  1.95it/s, v_num=2]{'loss': tensor(9.3785, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 348/1958 [02:58<13:44,  1.95it/s, v_num=2]{'loss': tensor(8.6694, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 349/1958 [02:58<13:44,  1.95it/s, v_num=2]{'loss': tensor(9.3693, grad_fn=<MeanBackward0>), 'train_EM': 0.9843592047691345, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 350/1958 [02:59<13:43,  1.95it/s, v_num=2]{'loss': tensor(9.9494, grad_fn=<MeanBackward0>), 'train_EM': 0.9843589663505554, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 351/1958 [02:59<13:42,  1.95it/s, v_num=2]{'loss': tensor(9.6755, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 352/1958 [03:00<13:41,  1.95it/s, v_num=2]{'loss': tensor(10.5081, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 353/1958 [03:00<13:40,  1.96it/s, v_num=2]{'loss': tensor(9.5236, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 354/1958 [03:01<13:40,  1.95it/s, v_num=2]{'loss': tensor(11.1005, grad_fn=<MeanBackward0>), 'train_EM': 0.9843554496765137, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 355/1958 [03:01<13:40,  1.95it/s, v_num=2]{'loss': tensor(11.7332, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 356/1958 [03:02<13:39,  1.95it/s, v_num=2]{'loss': tensor(10.1741, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 357/1958 [03:02<13:39,  1.95it/s, v_num=2]{'loss': tensor(10.5176, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 358/1958 [03:03<13:39,  1.95it/s, v_num=2]{'loss': tensor(9.8559, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 359/1958 [03:03<13:38,  1.95it/s, v_num=2]{'loss': tensor(8.7987, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 360/1958 [03:04<13:38,  1.95it/s, v_num=2]{'loss': tensor(11.5175, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 361/1958 [03:05<13:38,  1.95it/s, v_num=2]{'loss': tensor(9.9177, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  18%|█▊        | 362/1958 [03:05<13:38,  1.95it/s, v_num=2]{'loss': tensor(9.1628, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▊        | 363/1958 [03:06<13:38,  1.95it/s, v_num=2]{'loss': tensor(10.4946, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▊        | 364/1958 [03:06<13:37,  1.95it/s, v_num=2]{'loss': tensor(10.7183, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▊        | 365/1958 [03:07<13:37,  1.95it/s, v_num=2]{'loss': tensor(9.7325, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▊        | 366/1958 [03:07<13:36,  1.95it/s, v_num=2]{'loss': tensor(10.5823, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▊        | 367/1958 [03:08<13:36,  1.95it/s, v_num=2]{'loss': tensor(10.5502, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 368/1958 [03:08<13:35,  1.95it/s, v_num=2]{'loss': tensor(9.4554, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 369/1958 [03:09<13:35,  1.95it/s, v_num=2]{'loss': tensor(10.3860, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 370/1958 [03:09<13:35,  1.95it/s, v_num=2]{'loss': tensor(9.7455, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 371/1958 [03:10<13:34,  1.95it/s, v_num=2]{'loss': tensor(9.0101, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 372/1958 [03:10<13:34,  1.95it/s, v_num=2]{'loss': tensor(10.9322, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 373/1958 [03:11<13:33,  1.95it/s, v_num=2]{'loss': tensor(10.8156, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 374/1958 [03:11<13:32,  1.95it/s, v_num=2]{'loss': tensor(12.3583, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 375/1958 [03:12<13:32,  1.95it/s, v_num=2]{'loss': tensor(9.0664, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 376/1958 [03:12<13:31,  1.95it/s, v_num=2]{'loss': tensor(9.9121, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 377/1958 [03:13<13:30,  1.95it/s, v_num=2]{'loss': tensor(9.6138, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 378/1958 [03:13<13:29,  1.95it/s, v_num=2]{'loss': tensor(10.0708, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 379/1958 [03:14<13:29,  1.95it/s, v_num=2]{'loss': tensor(10.4202, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 380/1958 [03:14<13:29,  1.95it/s, v_num=2]{'loss': tensor(10.0632, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  19%|█▉        | 381/1958 [03:15<13:28,  1.95it/s, v_num=2]{'loss': tensor(9.3939, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 382/1958 [03:15<13:27,  1.95it/s, v_num=2]{'loss': tensor(10.2001, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 383/1958 [03:16<13:27,  1.95it/s, v_num=2]{'loss': tensor(9.4826, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 384/1958 [03:16<13:27,  1.95it/s, v_num=2]{'loss': tensor(9.9312, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 385/1958 [03:17<13:26,  1.95it/s, v_num=2]{'loss': tensor(11.0548, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 386/1958 [03:17<13:26,  1.95it/s, v_num=2]{'loss': tensor(9.7371, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 387/1958 [03:18<13:25,  1.95it/s, v_num=2]{'loss': tensor(8.9118, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 388/1958 [03:18<13:24,  1.95it/s, v_num=2]{'loss': tensor(9.6812, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 389/1958 [03:19<13:23,  1.95it/s, v_num=2]{'loss': tensor(8.3770, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 390/1958 [03:19<13:23,  1.95it/s, v_num=2]{'loss': tensor(9.3269, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|█▉        | 391/1958 [03:20<13:22,  1.95it/s, v_num=2]{'loss': tensor(9.8793, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 392/1958 [03:20<13:21,  1.95it/s, v_num=2]{'loss': tensor(9.8739, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 393/1958 [03:21<13:20,  1.95it/s, v_num=2]{'loss': tensor(9.3989, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 394/1958 [03:21<13:20,  1.95it/s, v_num=2]{'loss': tensor(10.0132, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 395/1958 [03:21<13:19,  1.96it/s, v_num=2]{'loss': tensor(9.9711, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 396/1958 [03:22<13:18,  1.96it/s, v_num=2]{'loss': tensor(10.8839, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 397/1958 [03:22<13:18,  1.96it/s, v_num=2]{'loss': tensor(10.3887, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 398/1958 [03:23<13:17,  1.96it/s, v_num=2]{'loss': tensor(10.8507, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 399/1958 [03:23<13:16,  1.96it/s, v_num=2]{'loss': tensor(9.6989, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 400/1958 [03:24<13:16,  1.96it/s, v_num=2]{'loss': tensor(11.4913, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  20%|██        | 401/1958 [03:24<13:15,  1.96it/s, v_num=2]{'loss': tensor(8.8599, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 402/1958 [03:25<13:14,  1.96it/s, v_num=2]{'loss': tensor(10.3704, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 403/1958 [03:25<13:14,  1.96it/s, v_num=2]{'loss': tensor(10.0716, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 404/1958 [03:26<13:13,  1.96it/s, v_num=2]{'loss': tensor(10.5671, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 405/1958 [03:26<13:12,  1.96it/s, v_num=2]{'loss': tensor(9.5463, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 406/1958 [03:27<13:12,  1.96it/s, v_num=2]{'loss': tensor(10.2645, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 407/1958 [03:27<13:11,  1.96it/s, v_num=2]{'loss': tensor(11.5404, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 408/1958 [03:28<13:10,  1.96it/s, v_num=2]{'loss': tensor(10.6556, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 409/1958 [03:28<13:10,  1.96it/s, v_num=2]{'loss': tensor(8.5458, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 410/1958 [03:29<13:09,  1.96it/s, v_num=2]{'loss': tensor(9.4833, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 411/1958 [03:29<13:08,  1.96it/s, v_num=2]{'loss': tensor(9.7548, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 412/1958 [03:30<13:08,  1.96it/s, v_num=2]{'loss': tensor(9.2602, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 413/1958 [03:30<13:07,  1.96it/s, v_num=2]{'loss': tensor(10.3270, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 414/1958 [03:31<13:07,  1.96it/s, v_num=2]{'loss': tensor(10.0083, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 415/1958 [03:31<13:06,  1.96it/s, v_num=2]{'loss': tensor(10.6767, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██        | 416/1958 [03:31<13:05,  1.96it/s, v_num=2]{'loss': tensor(9.4171, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██▏       | 417/1958 [03:32<13:04,  1.96it/s, v_num=2]{'loss': tensor(9.9372, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██▏       | 418/1958 [03:32<13:04,  1.96it/s, v_num=2]{'loss': tensor(10.2093, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██▏       | 419/1958 [03:33<13:03,  1.96it/s, v_num=2]{'loss': tensor(8.3741, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  21%|██▏       | 420/1958 [03:33<13:03,  1.96it/s, v_num=2]{'loss': tensor(7.9421, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 421/1958 [03:34<13:02,  1.96it/s, v_num=2]{'loss': tensor(11.5522, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 422/1958 [03:34<13:02,  1.96it/s, v_num=2]{'loss': tensor(8.8607, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 423/1958 [03:35<13:01,  1.96it/s, v_num=2]{'loss': tensor(9.0387, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 424/1958 [03:35<13:00,  1.96it/s, v_num=2]{'loss': tensor(8.4991, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 425/1958 [03:36<13:00,  1.96it/s, v_num=2]{'loss': tensor(9.3028, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 426/1958 [03:36<12:59,  1.96it/s, v_num=2]{'loss': tensor(10.6085, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 427/1958 [03:37<12:59,  1.96it/s, v_num=2]{'loss': tensor(11.5799, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 428/1958 [03:37<12:58,  1.97it/s, v_num=2]{'loss': tensor(9.9848, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 429/1958 [03:38<12:57,  1.97it/s, v_num=2]{'loss': tensor(8.8139, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 430/1958 [03:38<12:56,  1.97it/s, v_num=2]{'loss': tensor(9.5761, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 431/1958 [03:39<12:56,  1.97it/s, v_num=2]{'loss': tensor(9.1335, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 432/1958 [03:39<12:55,  1.97it/s, v_num=2]{'loss': tensor(10.0676, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 433/1958 [03:40<12:54,  1.97it/s, v_num=2]{'loss': tensor(9.7333, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 434/1958 [03:40<12:54,  1.97it/s, v_num=2]{'loss': tensor(10.5235, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 435/1958 [03:40<12:53,  1.97it/s, v_num=2]{'loss': tensor(11.1492, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 436/1958 [03:41<12:52,  1.97it/s, v_num=2]{'loss': tensor(10.4946, grad_fn=<MeanBackward0>), 'train_EM': 0.9843552112579346, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 437/1958 [03:41<12:51,  1.97it/s, v_num=2]{'loss': tensor(10.6185, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 438/1958 [03:42<12:51,  1.97it/s, v_num=2]{'loss': tensor(10.0335, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 439/1958 [03:42<12:50,  1.97it/s, v_num=2]{'loss': tensor(9.2884, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:  22%|██▏       | 440/1958 [03:43<12:50,  1.97it/s, v_num=2]{'loss': tensor(10.8221, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 441/1958 [03:43<12:49,  1.97it/s, v_num=2]{'loss': tensor(9.4357, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 442/1958 [03:44<12:49,  1.97it/s, v_num=2]{'loss': tensor(9.5312, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 443/1958 [03:44<12:48,  1.97it/s, v_num=2]{'loss': tensor(9.7931, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 444/1958 [03:45<12:48,  1.97it/s, v_num=2]{'loss': tensor(9.0442, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 445/1958 [03:45<12:48,  1.97it/s, v_num=2]{'loss': tensor(9.0710, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 446/1958 [03:46<12:47,  1.97it/s, v_num=2]{'loss': tensor(10.4894, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 447/1958 [03:46<12:46,  1.97it/s, v_num=2]{'loss': tensor(9.0735, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 448/1958 [03:47<12:46,  1.97it/s, v_num=2]{'loss': tensor(11.5467, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 449/1958 [03:48<12:46,  1.97it/s, v_num=2]{'loss': tensor(10.7122, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 450/1958 [03:48<12:46,  1.97it/s, v_num=2]{'loss': tensor(9.6580, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 451/1958 [03:49<12:45,  1.97it/s, v_num=2]{'loss': tensor(9.5232, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 452/1958 [03:49<12:44,  1.97it/s, v_num=2]{'loss': tensor(10.2778, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 453/1958 [03:50<12:44,  1.97it/s, v_num=2]{'loss': tensor(8.3728, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 454/1958 [03:50<12:43,  1.97it/s, v_num=2]{'loss': tensor(10.6162, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 455/1958 [03:50<12:42,  1.97it/s, v_num=2]{'loss': tensor(9.7641, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 456/1958 [03:51<12:42,  1.97it/s, v_num=2]{'loss': tensor(11.8665, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 457/1958 [03:51<12:41,  1.97it/s, v_num=2]{'loss': tensor(9.6197, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 458/1958 [03:52<12:41,  1.97it/s, v_num=2]{'loss': tensor(11.1025, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 459/1958 [03:53<12:41,  1.97it/s, v_num=2]{'loss': tensor(8.9025, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  23%|██▎       | 460/1958 [03:53<12:40,  1.97it/s, v_num=2]{'loss': tensor(8.4401, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▎       | 461/1958 [03:54<12:40,  1.97it/s, v_num=2]{'loss': tensor(10.2869, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▎       | 462/1958 [03:54<12:40,  1.97it/s, v_num=2]{'loss': tensor(9.7373, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▎       | 463/1958 [03:55<12:39,  1.97it/s, v_num=2]{'loss': tensor(9.7305, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▎       | 464/1958 [03:55<12:39,  1.97it/s, v_num=2]{'loss': tensor(8.8365, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▎       | 465/1958 [03:56<12:38,  1.97it/s, v_num=2]{'loss': tensor(8.9224, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 466/1958 [03:56<12:38,  1.97it/s, v_num=2]{'loss': tensor(9.7903, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 467/1958 [03:57<12:37,  1.97it/s, v_num=2]{'loss': tensor(9.7464, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 468/1958 [03:57<12:37,  1.97it/s, v_num=2]{'loss': tensor(9.5073, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 469/1958 [03:58<12:37,  1.97it/s, v_num=2]{'loss': tensor(8.9841, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 470/1958 [03:58<12:36,  1.97it/s, v_num=2]{'loss': tensor(8.7471, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 471/1958 [03:59<12:36,  1.97it/s, v_num=2]{'loss': tensor(10.1393, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 472/1958 [04:00<12:35,  1.97it/s, v_num=2]{'loss': tensor(11.4800, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 473/1958 [04:00<12:35,  1.97it/s, v_num=2]{'loss': tensor(9.4968, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 474/1958 [04:01<12:34,  1.97it/s, v_num=2]{'loss': tensor(10.4241, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 475/1958 [04:01<12:34,  1.97it/s, v_num=2]{'loss': tensor(9.0762, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 476/1958 [04:01<12:33,  1.97it/s, v_num=2]{'loss': tensor(10.7756, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 477/1958 [04:02<12:33,  1.97it/s, v_num=2]{'loss': tensor(10.4151, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 478/1958 [04:03<12:32,  1.97it/s, v_num=2]{'loss': tensor(10.2438, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  24%|██▍       | 479/1958 [04:03<12:32,  1.97it/s, v_num=2]{'loss': tensor(10.9801, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 480/1958 [04:04<12:32,  1.97it/s, v_num=2]{'loss': tensor(9.8340, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 481/1958 [04:04<12:31,  1.96it/s, v_num=2]{'loss': tensor(10.9765, grad_fn=<MeanBackward0>), 'train_EM': 0.9843553304672241, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 482/1958 [04:05<12:31,  1.96it/s, v_num=2]{'loss': tensor(10.7999, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 483/1958 [04:05<12:30,  1.96it/s, v_num=2]{'loss': tensor(9.0231, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 484/1958 [04:06<12:30,  1.96it/s, v_num=2]{'loss': tensor(10.3140, grad_fn=<MeanBackward0>), 'train_EM': 0.9843552112579346, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 485/1958 [04:06<12:29,  1.97it/s, v_num=2]{'loss': tensor(9.0939, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 486/1958 [04:07<12:29,  1.96it/s, v_num=2]{'loss': tensor(10.2820, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 487/1958 [04:07<12:28,  1.96it/s, v_num=2]{'loss': tensor(10.0239, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 488/1958 [04:08<12:28,  1.96it/s, v_num=2]{'loss': tensor(10.4597, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▍       | 489/1958 [04:08<12:27,  1.97it/s, v_num=2]{'loss': tensor(10.0644, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 490/1958 [04:09<12:26,  1.97it/s, v_num=2]{'loss': tensor(10.9905, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 491/1958 [04:09<12:26,  1.97it/s, v_num=2]{'loss': tensor(8.7733, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 492/1958 [04:10<12:25,  1.97it/s, v_num=2]{'loss': tensor(9.5368, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 493/1958 [04:10<12:25,  1.96it/s, v_num=2]{'loss': tensor(8.9642, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 494/1958 [04:11<12:25,  1.96it/s, v_num=2]{'loss': tensor(11.6081, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 495/1958 [04:11<12:24,  1.97it/s, v_num=2]{'loss': tensor(9.0217, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 496/1958 [04:12<12:23,  1.97it/s, v_num=2]{'loss': tensor(9.8852, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 497/1958 [04:12<12:23,  1.97it/s, v_num=2]{'loss': tensor(9.5610, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 498/1958 [04:13<12:22,  1.97it/s, v_num=2]{'loss': tensor(10.9334, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  25%|██▌       | 499/1958 [04:13<12:22,  1.97it/s, v_num=2]{'loss': tensor(8.5810, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 500/1958 [04:14<12:21,  1.97it/s, v_num=2]{'loss': tensor(9.1856, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 501/1958 [04:14<12:20,  1.97it/s, v_num=2]{'loss': tensor(9.2913, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 502/1958 [04:15<12:20,  1.97it/s, v_num=2]{'loss': tensor(9.7767, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 503/1958 [04:15<12:19,  1.97it/s, v_num=2]{'loss': tensor(10.0467, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 504/1958 [04:16<12:18,  1.97it/s, v_num=2]{'loss': tensor(8.8504, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 505/1958 [04:16<12:17,  1.97it/s, v_num=2]{'loss': tensor(10.1039, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 506/1958 [04:17<12:17,  1.97it/s, v_num=2]{'loss': tensor(10.7654, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 507/1958 [04:17<12:17,  1.97it/s, v_num=2]{'loss': tensor(11.4633, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 508/1958 [04:18<12:16,  1.97it/s, v_num=2]{'loss': tensor(9.9284, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 509/1958 [04:18<12:16,  1.97it/s, v_num=2]{'loss': tensor(9.3869, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 510/1958 [04:19<12:15,  1.97it/s, v_num=2]{'loss': tensor(9.4676, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 511/1958 [04:19<12:14,  1.97it/s, v_num=2]{'loss': tensor(9.2191, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 512/1958 [04:19<12:14,  1.97it/s, v_num=2]{'loss': tensor(9.5811, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▌       | 513/1958 [04:20<12:13,  1.97it/s, v_num=2]{'loss': tensor(9.3192, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▋       | 514/1958 [04:20<12:13,  1.97it/s, v_num=2]{'loss': tensor(9.2696, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▋       | 515/1958 [04:21<12:12,  1.97it/s, v_num=2]{'loss': tensor(9.1500, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▋       | 516/1958 [04:21<12:11,  1.97it/s, v_num=2]{'loss': tensor(9.8987, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▋       | 517/1958 [04:22<12:11,  1.97it/s, v_num=2]{'loss': tensor(10.1589, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  26%|██▋       | 518/1958 [04:22<12:10,  1.97it/s, v_num=2]{'loss': tensor(10.0043, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 519/1958 [04:23<12:09,  1.97it/s, v_num=2]{'loss': tensor(9.7911, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 520/1958 [04:23<12:09,  1.97it/s, v_num=2]{'loss': tensor(10.5592, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 521/1958 [04:24<12:08,  1.97it/s, v_num=2]{'loss': tensor(8.0420, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 522/1958 [04:24<12:07,  1.97it/s, v_num=2]{'loss': tensor(7.7659, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 523/1958 [04:25<12:07,  1.97it/s, v_num=2]{'loss': tensor(10.2383, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 524/1958 [04:25<12:06,  1.97it/s, v_num=2]{'loss': tensor(10.5552, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 525/1958 [04:26<12:06,  1.97it/s, v_num=2]{'loss': tensor(11.5290, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 526/1958 [04:26<12:05,  1.97it/s, v_num=2]{'loss': tensor(10.5906, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 527/1958 [04:27<12:05,  1.97it/s, v_num=2]{'loss': tensor(9.9991, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 528/1958 [04:27<12:04,  1.97it/s, v_num=2]{'loss': tensor(10.0779, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 529/1958 [04:28<12:04,  1.97it/s, v_num=2]{'loss': tensor(9.9692, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 530/1958 [04:28<12:03,  1.97it/s, v_num=2]{'loss': tensor(9.6140, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 531/1958 [04:29<12:03,  1.97it/s, v_num=2]{'loss': tensor(9.7378, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 532/1958 [04:29<12:02,  1.97it/s, v_num=2]{'loss': tensor(9.7984, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 533/1958 [04:30<12:02,  1.97it/s, v_num=2]{'loss': tensor(10.8406, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 534/1958 [04:30<12:01,  1.97it/s, v_num=2]{'loss': tensor(9.8170, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 535/1958 [04:31<12:00,  1.97it/s, v_num=2]{'loss': tensor(9.3114, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 536/1958 [04:31<12:00,  1.97it/s, v_num=2]{'loss': tensor(11.0794, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 537/1958 [04:31<11:59,  1.97it/s, v_num=2]{'loss': tensor(10.3208, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  27%|██▋       | 538/1958 [04:32<11:59,  1.97it/s, v_num=2]{'loss': tensor(10.1817, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 539/1958 [04:33<11:59,  1.97it/s, v_num=2]{'loss': tensor(10.0465, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 540/1958 [04:33<11:58,  1.97it/s, v_num=2]{'loss': tensor(8.7237, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 541/1958 [04:34<11:58,  1.97it/s, v_num=2]{'loss': tensor(11.0709, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 542/1958 [04:34<11:57,  1.97it/s, v_num=2]{'loss': tensor(10.9666, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 543/1958 [04:35<11:57,  1.97it/s, v_num=2]{'loss': tensor(9.1760, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 544/1958 [04:35<11:56,  1.97it/s, v_num=2]{'loss': tensor(10.6794, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 545/1958 [04:36<11:56,  1.97it/s, v_num=2]{'loss': tensor(10.6679, grad_fn=<MeanBackward0>), 'train_EM': 0.9843583703041077, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 546/1958 [04:36<11:55,  1.97it/s, v_num=2]{'loss': tensor(11.4415, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 547/1958 [04:37<11:55,  1.97it/s, v_num=2]{'loss': tensor(8.9870, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 548/1958 [04:37<11:55,  1.97it/s, v_num=2]{'loss': tensor(10.4218, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 549/1958 [04:38<11:54,  1.97it/s, v_num=2]{'loss': tensor(10.1115, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 550/1958 [04:38<11:54,  1.97it/s, v_num=2]{'loss': tensor(9.9154, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 551/1958 [04:39<11:53,  1.97it/s, v_num=2]{'loss': tensor(9.3400, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 552/1958 [04:39<11:53,  1.97it/s, v_num=2]{'loss': tensor(9.9221, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 553/1958 [04:40<11:52,  1.97it/s, v_num=2]{'loss': tensor(10.0421, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 554/1958 [04:40<11:51,  1.97it/s, v_num=2]{'loss': tensor(10.4482, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 555/1958 [04:41<11:51,  1.97it/s, v_num=2]{'loss': tensor(10.1377, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 556/1958 [04:42<11:51,  1.97it/s, v_num=2]{'loss': tensor(8.4986, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 557/1958 [04:42<11:50,  1.97it/s, v_num=2]{'loss': tensor(9.2826, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  28%|██▊       | 558/1958 [04:42<11:49,  1.97it/s, v_num=2]{'loss': tensor(10.1333, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▊       | 559/1958 [04:43<11:49,  1.97it/s, v_num=2]{'loss': tensor(10.1307, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▊       | 560/1958 [04:43<11:48,  1.97it/s, v_num=2]{'loss': tensor(10.3947, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▊       | 561/1958 [04:44<11:48,  1.97it/s, v_num=2]{'loss': tensor(9.4388, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▊       | 562/1958 [04:45<11:47,  1.97it/s, v_num=2]{'loss': tensor(10.8296, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 563/1958 [04:45<11:47,  1.97it/s, v_num=2]{'loss': tensor(7.8522, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 564/1958 [04:45<11:46,  1.97it/s, v_num=2]{'loss': tensor(9.3892, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 565/1958 [04:46<11:46,  1.97it/s, v_num=2]{'loss': tensor(10.4072, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 566/1958 [04:46<11:45,  1.97it/s, v_num=2]{'loss': tensor(10.3926, grad_fn=<MeanBackward0>), 'train_EM': 0.9843596816062927, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 567/1958 [04:47<11:45,  1.97it/s, v_num=2]{'loss': tensor(10.5968, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 568/1958 [04:47<11:44,  1.97it/s, v_num=2]{'loss': tensor(9.6206, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 569/1958 [04:48<11:44,  1.97it/s, v_num=2]{'loss': tensor(9.2665, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 570/1958 [04:48<11:43,  1.97it/s, v_num=2]{'loss': tensor(11.0457, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 571/1958 [04:49<11:42,  1.97it/s, v_num=2]{'loss': tensor(10.5992, grad_fn=<MeanBackward0>), 'train_EM': 0.9843550324440002, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 572/1958 [04:49<11:42,  1.97it/s, v_num=2]{'loss': tensor(10.4420, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 573/1958 [04:50<11:41,  1.97it/s, v_num=2]{'loss': tensor(9.5582, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 574/1958 [04:50<11:41,  1.97it/s, v_num=2]{'loss': tensor(10.0484, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 575/1958 [04:51<11:40,  1.97it/s, v_num=2]{'loss': tensor(10.6160, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 576/1958 [04:51<11:40,  1.97it/s, v_num=2]{'loss': tensor(10.8062, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  29%|██▉       | 577/1958 [04:52<11:39,  1.97it/s, v_num=2]{'loss': tensor(9.2308, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 578/1958 [04:52<11:38,  1.97it/s, v_num=2]{'loss': tensor(9.9568, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 579/1958 [04:53<11:38,  1.97it/s, v_num=2]{'loss': tensor(10.8383, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 580/1958 [04:53<11:37,  1.97it/s, v_num=2]{'loss': tensor(12.1012, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 581/1958 [04:54<11:37,  1.97it/s, v_num=2]{'loss': tensor(8.5901, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 582/1958 [04:54<11:37,  1.97it/s, v_num=2]{'loss': tensor(10.6108, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 583/1958 [04:55<11:36,  1.97it/s, v_num=2]{'loss': tensor(11.4329, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 584/1958 [04:55<11:36,  1.97it/s, v_num=2]{'loss': tensor(10.3371, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 585/1958 [04:56<11:35,  1.97it/s, v_num=2]{'loss': tensor(9.2771, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 586/1958 [04:56<11:35,  1.97it/s, v_num=2]{'loss': tensor(10.3449, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|██▉       | 587/1958 [04:57<11:34,  1.97it/s, v_num=2]{'loss': tensor(10.5882, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 588/1958 [04:57<11:34,  1.97it/s, v_num=2]{'loss': tensor(10.2813, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 589/1958 [04:58<11:33,  1.97it/s, v_num=2]{'loss': tensor(10.4687, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 590/1958 [04:59<11:33,  1.97it/s, v_num=2]{'loss': tensor(8.7356, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 591/1958 [04:59<11:32,  1.97it/s, v_num=2]{'loss': tensor(9.8774, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 592/1958 [05:00<11:32,  1.97it/s, v_num=2]{'loss': tensor(11.6367, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 593/1958 [05:00<11:31,  1.97it/s, v_num=2]{'loss': tensor(9.7592, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 594/1958 [05:01<11:31,  1.97it/s, v_num=2]{'loss': tensor(11.4727, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 595/1958 [05:01<11:30,  1.97it/s, v_num=2]{'loss': tensor(11.6178, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 596/1958 [05:01<11:30,  1.97it/s, v_num=2]{'loss': tensor(8.3502, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  30%|███       | 597/1958 [05:02<11:29,  1.97it/s, v_num=2]{'loss': tensor(8.7032, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 598/1958 [05:02<11:29,  1.97it/s, v_num=2]{'loss': tensor(9.4826, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 599/1958 [05:03<11:28,  1.97it/s, v_num=2]{'loss': tensor(10.0603, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 600/1958 [05:03<11:27,  1.97it/s, v_num=2]{'loss': tensor(10.5615, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 601/1958 [05:04<11:27,  1.97it/s, v_num=2]{'loss': tensor(9.6755, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 602/1958 [05:04<11:26,  1.97it/s, v_num=2]{'loss': tensor(10.1959, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 603/1958 [05:05<11:26,  1.97it/s, v_num=2]{'loss': tensor(9.9149, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 604/1958 [05:05<11:25,  1.98it/s, v_num=2]{'loss': tensor(10.0008, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 605/1958 [05:06<11:25,  1.97it/s, v_num=2]{'loss': tensor(10.8991, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 606/1958 [05:06<11:24,  1.97it/s, v_num=2]{'loss': tensor(11.3368, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 607/1958 [05:07<11:24,  1.97it/s, v_num=2]{'loss': tensor(9.5330, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 608/1958 [05:07<11:23,  1.97it/s, v_num=2]{'loss': tensor(9.7196, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 609/1958 [05:08<11:23,  1.97it/s, v_num=2]{'loss': tensor(11.2920, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 610/1958 [05:09<11:23,  1.97it/s, v_num=2]{'loss': tensor(10.8050, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███       | 611/1958 [05:09<11:22,  1.97it/s, v_num=2]{'loss': tensor(9.8297, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███▏      | 612/1958 [05:10<11:22,  1.97it/s, v_num=2]{'loss': tensor(9.0073, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███▏      | 613/1958 [05:10<11:21,  1.97it/s, v_num=2]{'loss': tensor(9.6036, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███▏      | 614/1958 [05:11<11:21,  1.97it/s, v_num=2]{'loss': tensor(10.2145, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███▏      | 615/1958 [05:11<11:20,  1.97it/s, v_num=2]{'loss': tensor(10.0484, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  31%|███▏      | 616/1958 [05:12<11:20,  1.97it/s, v_num=2]{'loss': tensor(8.8877, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 617/1958 [05:12<11:19,  1.97it/s, v_num=2]{'loss': tensor(8.6455, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 618/1958 [05:13<11:19,  1.97it/s, v_num=2]{'loss': tensor(10.3054, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 619/1958 [05:13<11:18,  1.97it/s, v_num=2]{'loss': tensor(11.3234, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 620/1958 [05:14<11:17,  1.97it/s, v_num=2]{'loss': tensor(11.1800, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 621/1958 [05:14<11:17,  1.97it/s, v_num=2]{'loss': tensor(9.7892, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 622/1958 [05:15<11:17,  1.97it/s, v_num=2]{'loss': tensor(11.1533, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 623/1958 [05:15<11:16,  1.97it/s, v_num=2]{'loss': tensor(8.9376, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 624/1958 [05:16<11:16,  1.97it/s, v_num=2]{'loss': tensor(10.8628, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 625/1958 [05:16<11:15,  1.97it/s, v_num=2]{'loss': tensor(10.7047, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 626/1958 [05:17<11:15,  1.97it/s, v_num=2]{'loss': tensor(9.1472, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 627/1958 [05:17<11:14,  1.97it/s, v_num=2]{'loss': tensor(9.5278, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 628/1958 [05:18<11:14,  1.97it/s, v_num=2]{'loss': tensor(9.5820, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 629/1958 [05:18<11:13,  1.97it/s, v_num=2]{'loss': tensor(8.5564, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 630/1958 [05:19<11:13,  1.97it/s, v_num=2]{'loss': tensor(9.8191, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 631/1958 [05:19<11:12,  1.97it/s, v_num=2]{'loss': tensor(9.1554, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 632/1958 [05:20<11:12,  1.97it/s, v_num=2]{'loss': tensor(10.0396, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 633/1958 [05:20<11:11,  1.97it/s, v_num=2]{'loss': tensor(8.5849, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 634/1958 [05:21<11:11,  1.97it/s, v_num=2]{'loss': tensor(10.7238, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 635/1958 [05:22<11:10,  1.97it/s, v_num=2]{'loss': tensor(9.4831, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  32%|███▏      | 636/1958 [05:22<11:10,  1.97it/s, v_num=2]{'loss': tensor(10.1268, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 637/1958 [05:23<11:10,  1.97it/s, v_num=2]{'loss': tensor(11.1124, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 638/1958 [05:23<11:09,  1.97it/s, v_num=2]{'loss': tensor(11.5833, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 639/1958 [05:24<11:09,  1.97it/s, v_num=2]{'loss': tensor(9.7774, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 640/1958 [05:24<11:08,  1.97it/s, v_num=2]{'loss': tensor(9.8332, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 641/1958 [05:25<11:07,  1.97it/s, v_num=2]{'loss': tensor(10.7948, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 642/1958 [05:25<11:07,  1.97it/s, v_num=2]{'loss': tensor(9.5127, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 643/1958 [05:26<11:06,  1.97it/s, v_num=2]{'loss': tensor(10.3332, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 644/1958 [05:26<11:06,  1.97it/s, v_num=2]{'loss': tensor(9.5573, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 645/1958 [05:27<11:05,  1.97it/s, v_num=2]{'loss': tensor(11.2008, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 646/1958 [05:27<11:05,  1.97it/s, v_num=2]{'loss': tensor(9.9922, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 647/1958 [05:28<11:04,  1.97it/s, v_num=2]{'loss': tensor(10.0787, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 648/1958 [05:28<11:04,  1.97it/s, v_num=2]{'loss': tensor(9.1261, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 649/1958 [05:29<11:04,  1.97it/s, v_num=2]{'loss': tensor(11.5595, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 650/1958 [05:29<11:03,  1.97it/s, v_num=2]{'loss': tensor(9.9327, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 651/1958 [05:30<11:03,  1.97it/s, v_num=2]{'loss': tensor(10.1875, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 652/1958 [05:30<11:02,  1.97it/s, v_num=2]{'loss': tensor(9.9485, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 653/1958 [05:31<11:02,  1.97it/s, v_num=2]{'loss': tensor(10.5720, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 654/1958 [05:31<11:01,  1.97it/s, v_num=2]{'loss': tensor(8.7270, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  33%|███▎      | 655/1958 [05:32<11:01,  1.97it/s, v_num=2]{'loss': tensor(11.4093, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▎      | 656/1958 [05:32<11:00,  1.97it/s, v_num=2]{'loss': tensor(8.9824, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▎      | 657/1958 [05:33<10:59,  1.97it/s, v_num=2]{'loss': tensor(10.1045, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▎      | 658/1958 [05:33<10:59,  1.97it/s, v_num=2]{'loss': tensor(9.0461, grad_fn=<MeanBackward0>), 'train_EM': 0.9843592047691345, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▎      | 659/1958 [05:34<10:58,  1.97it/s, v_num=2]{'loss': tensor(9.1476, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▎      | 660/1958 [05:34<10:58,  1.97it/s, v_num=2]{'loss': tensor(10.6008, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 661/1958 [05:35<10:57,  1.97it/s, v_num=2]{'loss': tensor(9.4546, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 662/1958 [05:35<10:57,  1.97it/s, v_num=2]{'loss': tensor(11.1519, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 663/1958 [05:36<10:56,  1.97it/s, v_num=2]{'loss': tensor(10.2227, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 664/1958 [05:36<10:56,  1.97it/s, v_num=2]{'loss': tensor(10.5179, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 665/1958 [05:37<10:56,  1.97it/s, v_num=2]{'loss': tensor(10.3615, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 666/1958 [05:37<10:55,  1.97it/s, v_num=2]{'loss': tensor(8.8220, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 667/1958 [05:38<10:54,  1.97it/s, v_num=2]{'loss': tensor(9.0213, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 668/1958 [05:38<10:54,  1.97it/s, v_num=2]{'loss': tensor(10.8091, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 669/1958 [05:39<10:53,  1.97it/s, v_num=2]{'loss': tensor(10.3753, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 670/1958 [05:39<10:53,  1.97it/s, v_num=2]{'loss': tensor(10.6970, grad_fn=<MeanBackward0>), 'train_EM': 0.9843550324440002, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 671/1958 [05:40<10:52,  1.97it/s, v_num=2]{'loss': tensor(9.6329, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 672/1958 [05:40<10:52,  1.97it/s, v_num=2]{'loss': tensor(9.6298, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 673/1958 [05:41<10:51,  1.97it/s, v_num=2]{'loss': tensor(9.7214, grad_fn=<MeanBackward0>), 'train_EM': 0.9843592047691345, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 674/1958 [05:41<10:50,  1.97it/s, v_num=2]{'loss': tensor(9.7397, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  34%|███▍      | 675/1958 [05:42<10:50,  1.97it/s, v_num=2]{'loss': tensor(10.5968, grad_fn=<MeanBackward0>), 'train_EM': 0.9843554496765137, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 676/1958 [05:42<10:50,  1.97it/s, v_num=2]{'loss': tensor(10.1020, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 677/1958 [05:43<10:49,  1.97it/s, v_num=2]{'loss': tensor(8.8896, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 678/1958 [05:43<10:49,  1.97it/s, v_num=2]{'loss': tensor(11.3472, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 679/1958 [05:44<10:48,  1.97it/s, v_num=2]{'loss': tensor(8.3750, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 680/1958 [05:45<10:48,  1.97it/s, v_num=2]{'loss': tensor(10.8308, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 681/1958 [05:45<10:48,  1.97it/s, v_num=2]{'loss': tensor(9.7019, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 682/1958 [05:46<10:47,  1.97it/s, v_num=2]{'loss': tensor(10.4604, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 683/1958 [05:46<10:47,  1.97it/s, v_num=2]{'loss': tensor(9.1782, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 684/1958 [05:47<10:46,  1.97it/s, v_num=2]{'loss': tensor(10.6621, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▍      | 685/1958 [05:47<10:46,  1.97it/s, v_num=2]{'loss': tensor(10.3539, grad_fn=<MeanBackward0>), 'train_EM': 0.9843552112579346, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 686/1958 [05:48<10:45,  1.97it/s, v_num=2]{'loss': tensor(9.2305, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 687/1958 [05:48<10:45,  1.97it/s, v_num=2]{'loss': tensor(8.5024, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 688/1958 [05:49<10:44,  1.97it/s, v_num=2]{'loss': tensor(9.1712, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 689/1958 [05:49<10:44,  1.97it/s, v_num=2]{'loss': tensor(10.4851, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 690/1958 [05:50<10:43,  1.97it/s, v_num=2]{'loss': tensor(10.2383, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 691/1958 [05:50<10:43,  1.97it/s, v_num=2]{'loss': tensor(9.9016, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 692/1958 [05:51<10:42,  1.97it/s, v_num=2]{'loss': tensor(11.0770, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 693/1958 [05:51<10:42,  1.97it/s, v_num=2]{'loss': tensor(7.6546, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 694/1958 [05:52<10:41,  1.97it/s, v_num=2]{'loss': tensor(9.7266, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  35%|███▌      | 695/1958 [05:52<10:41,  1.97it/s, v_num=2]{'loss': tensor(9.8521, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 696/1958 [05:53<10:41,  1.97it/s, v_num=2]{'loss': tensor(9.0184, grad_fn=<MeanBackward0>), 'train_EM': 0.9843587279319763, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 697/1958 [05:54<10:40,  1.97it/s, v_num=2]{'loss': tensor(11.9066, grad_fn=<MeanBackward0>), 'train_EM': 0.9843555688858032, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 698/1958 [05:54<10:40,  1.97it/s, v_num=2]{'loss': tensor(9.6527, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 699/1958 [05:55<10:40,  1.97it/s, v_num=2]{'loss': tensor(9.8501, grad_fn=<MeanBackward0>), 'train_EM': 0.9843544363975525, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 700/1958 [05:56<10:39,  1.97it/s, v_num=2]{'loss': tensor(10.1777, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 701/1958 [05:56<10:39,  1.97it/s, v_num=2]{'loss': tensor(10.2713, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 702/1958 [05:57<10:38,  1.97it/s, v_num=2]{'loss': tensor(9.5686, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 703/1958 [05:57<10:38,  1.97it/s, v_num=2]{'loss': tensor(10.7397, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 704/1958 [05:58<10:37,  1.97it/s, v_num=2]{'loss': tensor(9.1408, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 705/1958 [05:58<10:37,  1.97it/s, v_num=2]{'loss': tensor(9.7919, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 706/1958 [05:59<10:36,  1.97it/s, v_num=2]{'loss': tensor(9.7255, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 707/1958 [05:59<10:36,  1.97it/s, v_num=2]{'loss': tensor(9.2075, grad_fn=<MeanBackward0>), 'train_EM': 0.984359085559845, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 708/1958 [06:00<10:36,  1.96it/s, v_num=2]{'loss': tensor(9.1518, grad_fn=<MeanBackward0>), 'train_EM': 0.984359085559845, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▌      | 709/1958 [06:01<10:35,  1.96it/s, v_num=2]{'loss': tensor(10.8493, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▋      | 710/1958 [06:01<10:35,  1.96it/s, v_num=2]{'loss': tensor(9.5048, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▋      | 711/1958 [06:02<10:35,  1.96it/s, v_num=2]{'loss': tensor(9.2096, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▋      | 712/1958 [06:02<10:34,  1.96it/s, v_num=2]{'loss': tensor(9.9435, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▋      | 713/1958 [06:03<10:34,  1.96it/s, v_num=2]{'loss': tensor(10.4898, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  36%|███▋      | 714/1958 [06:03<10:33,  1.96it/s, v_num=2]{'loss': tensor(10.2193, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 715/1958 [06:04<10:33,  1.96it/s, v_num=2]{'loss': tensor(10.8844, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 716/1958 [06:04<10:32,  1.96it/s, v_num=2]{'loss': tensor(10.4068, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 717/1958 [06:05<10:32,  1.96it/s, v_num=2]{'loss': tensor(10.1636, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 718/1958 [06:05<10:31,  1.96it/s, v_num=2]{'loss': tensor(10.2922, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 719/1958 [06:06<10:31,  1.96it/s, v_num=2]{'loss': tensor(9.9324, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 720/1958 [06:06<10:30,  1.96it/s, v_num=2]{'loss': tensor(10.5087, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 721/1958 [06:07<10:30,  1.96it/s, v_num=2]{'loss': tensor(10.8967, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 722/1958 [06:07<10:29,  1.96it/s, v_num=2]{'loss': tensor(10.4987, grad_fn=<MeanBackward0>), 'train_EM': 0.9843562841415405, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 723/1958 [06:08<10:29,  1.96it/s, v_num=2]{'loss': tensor(9.9983, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 724/1958 [06:08<10:28,  1.96it/s, v_num=2]{'loss': tensor(10.4205, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 725/1958 [06:09<10:28,  1.96it/s, v_num=2]{'loss': tensor(10.5978, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 726/1958 [06:10<10:28,  1.96it/s, v_num=2]{'loss': tensor(9.1648, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 727/1958 [06:10<10:27,  1.96it/s, v_num=2]{'loss': tensor(10.8551, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 728/1958 [06:11<10:26,  1.96it/s, v_num=2]{'loss': tensor(9.7945, grad_fn=<MeanBackward0>), 'train_EM': 0.9843556880950928, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 729/1958 [06:11<10:26,  1.96it/s, v_num=2]{'loss': tensor(10.0288, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 730/1958 [06:12<10:25,  1.96it/s, v_num=2]{'loss': tensor(10.6709, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 731/1958 [06:12<10:25,  1.96it/s, v_num=2]{'loss': tensor(9.6104, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 732/1958 [06:13<10:25,  1.96it/s, v_num=2]{'loss': tensor(12.0213, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 733/1958 [06:13<10:24,  1.96it/s, v_num=2]{'loss': tensor(10.6111, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  37%|███▋      | 734/1958 [06:14<10:23,  1.96it/s, v_num=2]{'loss': tensor(10.6935, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 735/1958 [06:14<10:23,  1.96it/s, v_num=2]{'loss': tensor(11.3727, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 736/1958 [06:15<10:22,  1.96it/s, v_num=2]{'loss': tensor(11.1601, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 737/1958 [06:15<10:22,  1.96it/s, v_num=2]{'loss': tensor(10.7236, grad_fn=<MeanBackward0>), 'train_EM': 0.9843547940254211, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 738/1958 [06:16<10:21,  1.96it/s, v_num=2]{'loss': tensor(10.0034, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 739/1958 [06:16<10:21,  1.96it/s, v_num=2]{'loss': tensor(9.6275, grad_fn=<MeanBackward0>), 'train_EM': 0.9843559265136719, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 740/1958 [06:17<10:20,  1.96it/s, v_num=2]{'loss': tensor(10.6167, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 741/1958 [06:17<10:20,  1.96it/s, v_num=2]{'loss': tensor(10.1201, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 742/1958 [06:18<10:20,  1.96it/s, v_num=2]{'loss': tensor(8.7729, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 743/1958 [06:18<10:19,  1.96it/s, v_num=2]{'loss': tensor(9.6913, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 744/1958 [06:19<10:19,  1.96it/s, v_num=2]{'loss': tensor(9.8222, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 745/1958 [06:20<10:18,  1.96it/s, v_num=2]{'loss': tensor(10.2936, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 746/1958 [06:20<10:18,  1.96it/s, v_num=2]{'loss': tensor(9.8045, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 747/1958 [06:21<10:17,  1.96it/s, v_num=2]{'loss': tensor(10.0715, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 748/1958 [06:21<10:17,  1.96it/s, v_num=2]{'loss': tensor(9.5625, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 749/1958 [06:21<10:16,  1.96it/s, v_num=2]{'loss': tensor(9.4115, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 750/1958 [06:22<10:16,  1.96it/s, v_num=2]{'loss': tensor(9.4458, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 751/1958 [06:23<10:15,  1.96it/s, v_num=2]{'loss': tensor(8.6734, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 752/1958 [06:23<10:15,  1.96it/s, v_num=2]{'loss': tensor(10.3088, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  38%|███▊      | 753/1958 [06:24<10:14,  1.96it/s, v_num=2]{'loss': tensor(11.3175, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▊      | 754/1958 [06:24<10:14,  1.96it/s, v_num=2]{'loss': tensor(10.0013, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▊      | 755/1958 [06:25<10:14,  1.96it/s, v_num=2]{'loss': tensor(10.0354, grad_fn=<MeanBackward0>), 'train_EM': 0.9843577146530151, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▊      | 756/1958 [06:25<10:13,  1.96it/s, v_num=2]{'loss': tensor(10.0226, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▊      | 757/1958 [06:26<10:13,  1.96it/s, v_num=2]{'loss': tensor(11.1018, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▊      | 758/1958 [06:26<10:12,  1.96it/s, v_num=2]{'loss': tensor(9.1220, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 759/1958 [06:27<10:11,  1.96it/s, v_num=2]{'loss': tensor(9.4125, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 760/1958 [06:27<10:11,  1.96it/s, v_num=2]{'loss': tensor(9.8783, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 761/1958 [06:28<10:10,  1.96it/s, v_num=2]{'loss': tensor(9.9831, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 762/1958 [06:28<10:10,  1.96it/s, v_num=2]{'loss': tensor(10.3342, grad_fn=<MeanBackward0>), 'train_EM': 0.984359085559845, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 763/1958 [06:29<10:09,  1.96it/s, v_num=2]{'loss': tensor(9.8618, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 764/1958 [06:29<10:09,  1.96it/s, v_num=2]{'loss': tensor(9.5331, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 765/1958 [06:30<10:09,  1.96it/s, v_num=2]{'loss': tensor(10.5593, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 766/1958 [06:31<10:08,  1.96it/s, v_num=2]{'loss': tensor(10.6521, grad_fn=<MeanBackward0>), 'train_EM': 0.9843588471412659, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 767/1958 [06:31<10:08,  1.96it/s, v_num=2]{'loss': tensor(10.6751, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 768/1958 [06:32<10:07,  1.96it/s, v_num=2]{'loss': tensor(9.5293, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 769/1958 [06:32<10:06,  1.96it/s, v_num=2]{'loss': tensor(9.8265, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 770/1958 [06:33<10:06,  1.96it/s, v_num=2]{'loss': tensor(10.8532, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 771/1958 [06:33<10:05,  1.96it/s, v_num=2]{'loss': tensor(9.9603, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 772/1958 [06:34<10:05,  1.96it/s, v_num=2]{'loss': tensor(9.5920, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  39%|███▉      | 773/1958 [06:34<10:04,  1.96it/s, v_num=2]{'loss': tensor(11.1201, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 774/1958 [06:35<10:04,  1.96it/s, v_num=2]{'loss': tensor(8.7274, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 775/1958 [06:35<10:03,  1.96it/s, v_num=2]{'loss': tensor(9.4739, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 776/1958 [06:36<10:03,  1.96it/s, v_num=2]{'loss': tensor(10.9044, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 777/1958 [06:36<10:02,  1.96it/s, v_num=2]{'loss': tensor(8.8399, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 778/1958 [06:37<10:02,  1.96it/s, v_num=2]{'loss': tensor(9.3127, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 779/1958 [06:37<10:01,  1.96it/s, v_num=2]{'loss': tensor(9.2341, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 780/1958 [06:38<10:01,  1.96it/s, v_num=2]{'loss': tensor(9.6253, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 781/1958 [06:38<10:01,  1.96it/s, v_num=2]{'loss': tensor(8.5711, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 782/1958 [06:39<10:00,  1.96it/s, v_num=2]{'loss': tensor(10.7478, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|███▉      | 783/1958 [06:39<10:00,  1.96it/s, v_num=2]{'loss': tensor(9.1266, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 784/1958 [06:40<09:59,  1.96it/s, v_num=2]{'loss': tensor(10.0461, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 785/1958 [06:41<09:59,  1.96it/s, v_num=2]{'loss': tensor(10.8426, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 786/1958 [06:41<09:58,  1.96it/s, v_num=2]{'loss': tensor(9.3507, grad_fn=<MeanBackward0>), 'train_EM': 0.9843589663505554, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 787/1958 [06:42<09:58,  1.96it/s, v_num=2]{'loss': tensor(9.9385, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 788/1958 [06:42<09:58,  1.96it/s, v_num=2]{'loss': tensor(9.2827, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 789/1958 [06:43<09:57,  1.96it/s, v_num=2]{'loss': tensor(9.1092, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 790/1958 [06:43<09:57,  1.96it/s, v_num=2]{'loss': tensor(9.3196, grad_fn=<MeanBackward0>), 'train_EM': 0.9843580722808838, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 791/1958 [06:44<09:56,  1.96it/s, v_num=2]{'loss': tensor(10.2234, grad_fn=<MeanBackward0>), 'train_EM': 0.9843560457229614, 'train_F1': 0.9}\n",
      "Epoch 0:  40%|████      | 792/1958 [06:44<09:56,  1.96it/s, v_num=2]{'loss': tensor(10.0199, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 793/1958 [06:45<09:55,  1.96it/s, v_num=2]{'loss': tensor(9.5917, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 794/1958 [06:46<09:55,  1.95it/s, v_num=2]{'loss': tensor(12.5900, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 795/1958 [06:46<09:54,  1.95it/s, v_num=2]{'loss': tensor(9.7252, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 796/1958 [06:47<09:54,  1.95it/s, v_num=2]{'loss': tensor(8.7862, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 797/1958 [06:47<09:54,  1.95it/s, v_num=2]{'loss': tensor(9.1699, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 798/1958 [06:48<09:53,  1.95it/s, v_num=2]{'loss': tensor(8.5443, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 799/1958 [06:48<09:53,  1.95it/s, v_num=2]{'loss': tensor(9.4719, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 800/1958 [06:49<09:52,  1.95it/s, v_num=2]{'loss': tensor(8.9618, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 801/1958 [06:49<09:52,  1.95it/s, v_num=2]{'loss': tensor(10.5004, grad_fn=<MeanBackward0>), 'train_EM': 0.984357476234436, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 802/1958 [06:50<09:51,  1.95it/s, v_num=2]{'loss': tensor(9.7879, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 803/1958 [06:51<09:51,  1.95it/s, v_num=2]{'loss': tensor(11.1181, grad_fn=<MeanBackward0>), 'train_EM': 0.9843567609786987, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 804/1958 [06:51<09:50,  1.95it/s, v_num=2]{'loss': tensor(8.3758, grad_fn=<MeanBackward0>), 'train_EM': 0.9843575954437256, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 805/1958 [06:52<09:50,  1.95it/s, v_num=2]{'loss': tensor(10.1973, grad_fn=<MeanBackward0>), 'train_EM': 0.9843571186065674, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 806/1958 [06:52<09:49,  1.95it/s, v_num=2]{'loss': tensor(10.1590, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████      | 807/1958 [06:53<09:49,  1.95it/s, v_num=2]{'loss': tensor(10.3883, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████▏     | 808/1958 [06:53<09:48,  1.95it/s, v_num=2]{'loss': tensor(7.9789, grad_fn=<MeanBackward0>), 'train_EM': 0.9843586087226868, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████▏     | 809/1958 [06:54<09:48,  1.95it/s, v_num=2]{'loss': tensor(8.6290, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████▏     | 810/1958 [06:54<09:47,  1.95it/s, v_num=2]{'loss': tensor(9.9521, grad_fn=<MeanBackward0>), 'train_EM': 0.984356164932251, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████▏     | 811/1958 [06:55<09:47,  1.95it/s, v_num=2]{'loss': tensor(9.6811, grad_fn=<MeanBackward0>), 'train_EM': 0.9843568801879883, 'train_F1': 0.9}\n",
      "Epoch 0:  41%|████▏     | 812/1958 [06:55<09:46,  1.95it/s, v_num=2]{'loss': tensor(9.4660, grad_fn=<MeanBackward0>), 'train_EM': 0.9843558073043823, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 813/1958 [06:56<09:46,  1.95it/s, v_num=2]{'loss': tensor(12.3009, grad_fn=<MeanBackward0>), 'train_EM': 0.9843564033508301, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 814/1958 [06:56<09:45,  1.95it/s, v_num=2]{'loss': tensor(9.6670, grad_fn=<MeanBackward0>), 'train_EM': 0.9843565225601196, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 815/1958 [06:57<09:45,  1.95it/s, v_num=2]{'loss': tensor(9.4441, grad_fn=<MeanBackward0>), 'train_EM': 0.9843579530715942, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 816/1958 [06:58<09:45,  1.95it/s, v_num=2]{'loss': tensor(8.4587, grad_fn=<MeanBackward0>), 'train_EM': 0.9843584895133972, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 817/1958 [06:58<09:44,  1.95it/s, v_num=2]{'loss': tensor(10.3844, grad_fn=<MeanBackward0>), 'train_EM': 0.9843566417694092, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 818/1958 [06:59<09:44,  1.95it/s, v_num=2]{'loss': tensor(9.0053, grad_fn=<MeanBackward0>), 'train_EM': 0.9843573570251465, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 819/1958 [06:59<09:43,  1.95it/s, v_num=2]{'loss': tensor(10.3019, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 820/1958 [07:00<09:43,  1.95it/s, v_num=2]{'loss': tensor(9.8289, grad_fn=<MeanBackward0>), 'train_EM': 0.9843572378158569, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 821/1958 [07:00<09:43,  1.95it/s, v_num=2]{'loss': tensor(10.0902, grad_fn=<MeanBackward0>), 'train_EM': 0.9843582510948181, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 822/1958 [07:01<09:42,  1.95it/s, v_num=2]{'loss': tensor(9.5191, grad_fn=<MeanBackward0>), 'train_EM': 0.9843578338623047, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 823/1958 [07:02<09:42,  1.95it/s, v_num=2]{'loss': tensor(10.4196, grad_fn=<MeanBackward0>), 'train_EM': 0.9843569993972778, 'train_F1': 0.9}\n",
      "Epoch 0:  42%|████▏     | 824/1958 [07:02<09:41,  1.95it/s, v_num=2]"
     ]
    }
   ],
   "source": [
    "from babl.models import MODELS_CHOICES, MODELS\n",
    "from babl.config import T5 as T5Config\n",
    "from pathlib import Path\n",
    "\n",
    "model_name = \"t5\"\n",
    "full_model_name = MODELS_CHOICES[model_name][0]\n",
    "t_w_m = MODELS[model_name]\n",
    "\n",
    "t = t_w_m[\"tok\"]\n",
    "m = t_w_m[\"model\"]\n",
    "\n",
    "tokenizer = t.from_pretrained(full_model_name)\n",
    "model = m.from_pretrained(full_model_name, **T5Config().__dict__)\n",
    "\n",
    "# placing in training mode \n",
    "\n",
    "model.train()\n",
    "\n",
    "data_path_root = Path(\"/home/nameduser/Code/babl/inputs\")\n",
    "\n",
    "# # data_path_val = data_path_root / \"10k.jsonl\"\n",
    "# # ds = TextDataset(data_path_val, tokenizer=t, plain_text=False)\n",
    "# # from babl.data import T2TDataCollator\n",
    "# # from torch.utils.data import DataLoader\n",
    "# # t_dl = DataLoader(ds, batch_size=64, shuffle=True, collate_fn=T2TDataCollator())\n",
    "# # test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "# # data_module = TextDataModule(data_path, tokenizer)\n",
    "\n",
    "Fitter(model=model, model_name=full_model_name, tokenizer=tokenizer, data_path=data_path_root)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b in t_dl:\n",
    "#     # print(b)\n",
    "#     m(**b)\n",
    "\n",
    "import torch.nn.functional as F \n",
    "\n",
    "\n",
    "y = torch.tensor([[ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100],\n",
    "                  [ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100],\n",
    "                  [ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100],\n",
    "                  [ 822,   10,  125, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  213, 100, 100, 100],\n",
    "                  [ 822,   10,  116, 100, 100, 100]], dtype=torch.long\n",
    ")\n",
    "y_hat = torch.tensor([[-20.2879,  -9.8936, -13.5965, -40.7275, -40.8642, -40.8486],\n",
    "         [-34.0870,  -3.6627, -14.2458,  -46.1296, -46.3147, -46.2990],\n",
    "         [-30.5974,  -3.4536, -15.5923,  -43.6581, -43.8461, -43.8219],\n",
    "         [-18.1922,  -8.0767, -14.5352,  -45.5706, -45.7357, -45.7194],\n",
    "         [-18.1516,  -8.0787, -14.4750,  -45.4796, -45.6429, -45.6272],\n",
    "         [-18.1262,  -8.1061, -14.4559,  -45.4136, -45.5755, -45.5602],\n",
    "         [-17.2200,  -9.7170, -14.2499,  -38.4455, -38.5326, -38.4609],\n",
    "         [-34.3804,  -6.2359, -13.2374,  -42.5014, -42.6473, -42.5558],\n",
    "         [-27.8060,  -7.1265, -15.4786,  -42.2502, -42.3610, -42.2977],\n",
    "         [-17.2795,  -7.8251, -15.8752,  -44.6078, -44.7242, -44.6339],\n",
    "         [-17.1784,  -7.7900, -15.8198,   -44.4029, -44.5184, -44.4275],\n",
    "         [-17.1213,  -7.7632, -15.7711,   -44.2831, -44.3977, -44.3082]]) \n",
    "\n",
    "num_class= 1321\n",
    "y_hat = torch.stack([y_hat]*num_class, dim=2)\n",
    "\n",
    "y_hat.shape\n",
    "y.shape\n",
    "# y.shape\n",
    "# y_hat.shape\n",
    "y = F.one_hot(y, num_classes=1321)\n",
    "y = y.float()\n",
    "\n",
    "y.shape == y_hat.shape\n",
    "\n",
    "y_hat = F.softmax(y_hat, dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "losses = []\n",
    "for tok in range(y_hat.shape[1]):\n",
    "    print(y[:,tok,:].shape)\n",
    "    print(y_hat[:,tok,:].shape)\n",
    "    loss = F.cross_entropy(y_hat[:,tok,:] , y[:,tok,:])\n",
    "    print(loss)\n",
    "    # loss = F.nll_loss(y_hat[:,tok,:] , y[:,tok,:])\n",
    "    losses.append(loss)\n",
    "\n",
    "\n",
    "torch.tensor(losses).mean()\n",
    "# yx = F.one_hot(y, num_classes=1321)[:,0,:].shape\n",
    "\n",
    "# loss = F.nll_loss(y_hat , y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path_root = Path(\"/home/nameduser/Code/babl/inputs\")\n",
    "\n",
    "data_path_val = data_path_root / \"10k.jsonl\"\n",
    "ds = TextDataset(data_path_val, tokenizer=t, plain_text=True )\n",
    "\n",
    "# from babl.data import T2TDataCollator\n",
    "# from torch.utils.data import DataLoader\n",
    "# t_dl = DataLoader(ds, batch_size=64, shuffle=True, collate_fn=T2TDataCollator())\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "# data_module = TextDataModule(data_path, tokenizer)\n",
    "\n",
    "\n",
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([0,1,1,0,0,1])\n",
    "\n",
    "yh=  torch.tensor([0,1,1,0,1,1])\n",
    "(y == yh).int()\n",
    "\n",
    "\n",
    "torch.prod(torch.tensor(torch.rand((10,10)).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed (1414)\n",
    "\n",
    "t = torch.randn (8, 4)\n",
    "a = t.argmax(1)\n",
    "m = torch.zeros(t.shape).scatter(1, a.unsqueeze(1), 1.0)\n",
    "\n",
    "\n",
    "print ('\\n', t, '\\n\\n', a, '\\n\\n', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list({\"x\": [1, 2, 3, 4]}.values())[0].__len__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babl-qoEDH0A2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
